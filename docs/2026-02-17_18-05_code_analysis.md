# Code Analysis for Spec Derivation
## Scope
Entire codebase at neuromorphic-lab/

## Feature Detective Report

# Feature Detective Report -- SpikeCore Lab

## System Overview

SpikeCore Lab is a Python library and Jupyter notebook environment that provides a complete neuromorphic compilation pipeline. It allows users to compile neural network models into assembly for a fictional neuromorphic hardware target ("SpikeCore"), simulate execution on virtual hardware, and visualize results. The system has two execution paths: a TVM BYOC path (requiring TVM inside Docker) and a standalone path (no TVM required).

**User Roles Identified:** This is a single-role system. The user is an **AI/ML Engineer or Researcher** exploring neuromorphic compilation. There are no authentication, authorization, or multi-role mechanisms.

---

## Feature Area 1: Neural Network Compilation to SpikeCore Assembly

### FD-001: Compile PyTorch Model Weights to SpikeCore Assembly (Standalone Path)

- **Role:** ML Engineer / Researcher
- **Goal:** Convert a trained PyTorch model's weights and layer configuration into SpikeCore neuromorphic assembly instructions without needing TVM installed.
- **Entry:** Python API call to `compile_from_torch(state_dict, layer_configs)`
- **Capability:** User provides a dictionary of numpy weight arrays (keyed like `"layers.0.weight"`) and a list of per-layer configuration dicts specifying `name`, `in_features`, `out_features`, and `activation` type. The function quantizes weights to int8 and generates a list of `Instruction` objects plus quantized weight data.
- **Inputs:**
  - `state_dict`: dict mapping string keys to numpy float32 arrays (model weights)
  - `layer_configs`: list of dicts with keys `name` (str), `in_features` (int), `out_features` (int), `activation` ("relu" or None)
- **Outputs:**
  - Tuple of `(program: list[Instruction], quantized_weights: list[tuple[np.ndarray, float]])` where program contains ACC/FIRE/LEAK/HALT instructions and quantized_weights contains (int8_array, scale) per layer.
  - For layers with `activation="relu"`: generates ACC + FIRE + LEAK per output neuron
  - For layers with `activation=None`: generates ACC only per output neuron
  - Program always ends with HALT
- **Constraints:**
  - State dict keys must follow the pattern `"{name}.weight"` matching the layer config names
  - Weight matrices must be float32 numpy arrays
  - The FIRE shift parameter is computed automatically from fan-in: `ceil(log2(fan_in)) + 7`
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py` lines 155-215

---

### FD-002: Compile Weight/Bias Arrays Directly to SpikeCore Assembly

- **Role:** ML Engineer / Researcher
- **Goal:** Compile neural network layers to SpikeCore assembly using raw weight and bias matrices, without requiring PyTorch state_dict format.
- **Entry:** Python API call to `compile_nn_to_spikecore(weights, biases, activations)`
- **Capability:** A higher-level compilation function that accepts lists of weight matrices, bias vectors, and activation types directly. Quantizes all weights and biases, then generates the instruction program.
- **Inputs:**
  - `weights`: list of float32 numpy weight matrices (one per layer, shape `(out_features, in_features)`)
  - `biases`: list of float32 numpy bias vectors (one per layer)
  - `activations`: list of activation types per layer (`"relu"` or `None`)
- **Outputs:**
  - Tuple of `(program, quantized_weights, quantized_biases)` where both weight/bias outputs are lists of `(int8_array, scale)` tuples
- **Constraints:**
  - All three input lists must be the same length
  - Weight matrix shape `[0]` = out_features determines the number of cores allocated
  - Core IDs are assigned sequentially across layers (e.g., layer 0 uses cores 0..63, layer 1 uses cores 64..73)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py` lines 218-259

---

### FD-003: Register SpikeCore as a TVM BYOC Target

- **Role:** ML Engineer / Researcher (with TVM installed)
- **Goal:** Register "spikecore" as a recognized external codegen target within TVM's compilation framework.
- **Entry:** Python API call to `register_spikecore_target()`
- **Capability:** Registers two TVM functions: `relay.ext.spikecore` (the codegen callback that converts Relay subgraphs into SpikeCore assembly text) and `relay.ext.spikecore.cost_estimator` (returns cost=1, always preferring offload to SpikeCore). After registration, TVM's `AnnotateTarget(["spikecore"])` pass will recognize SpikeCore-compatible subgraphs.
- **Inputs:** None
- **Outputs:** Side effect -- TVM internal function registry is updated
- **Constraints:** Requires TVM to be installed. Raises `RuntimeError("TVM is required for BYOC target registration")` if TVM is absent.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py` lines 95-114

---

### FD-004: Partition Relay Graph for SpikeCore Offload

- **Role:** ML Engineer / Researcher (with TVM installed)
- **Goal:** Split a TVM Relay module into host subgraphs and SpikeCore-offloaded subgraphs using TVM's BYOC partitioning pipeline.
- **Entry:** Python API call to `partition_for_spikecore(mod, params)`
- **Capability:** Runs the three-pass BYOC pipeline: MergeComposite (fuses matching operator patterns), AnnotateTarget (marks fused regions for "spikecore"), PartitionGraph (splits the graph). Returns the partitioned module.
- **Inputs:**
  - `mod`: TVM IRModule containing a Relay function
  - `params`: dict of bound parameter NDArrays
- **Outputs:** Partitioned `tvm.IRModule` with SpikeCore subgraphs marked for offload
- **Constraints:** Requires TVM. Uses `opt_level=3` in the pass context.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py` lines 117-148

---

## Feature Area 2: Relay Pattern Matching

### FD-005: Retrieve SpikeCore Composite Pattern Table

- **Role:** ML Engineer / Researcher (with TVM installed)
- **Goal:** Obtain the list of Relay operator patterns that SpikeCore can accelerate, for use with TVM's MergeComposite transform.
- **Entry:** Python API call to `spikecore_pattern_table()`
- **Capability:** Returns three named patterns mapping Relay subgraphs to SpikeCore primitives:
  1. `spikecore.dense_relu` -- matches `nn.dense + bias_add + relu` (float path, hidden layers with activation)
  2. `spikecore.dense_bias` -- matches `nn.dense + bias_add` (output layer, no activation)
  3. `spikecore.qnn_dense_clip` -- matches `qnn.dense + add + clip(0,127)` (quantized path)
- **Inputs:** None
- **Outputs:** List of `(pattern_name: str, pattern: DFPattern)` tuples
- **Constraints:** Requires TVM. Raises `RuntimeError("TVM is required for pattern table generation")` if TVM is absent.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/relay_patterns.py` lines 65-78

---

## Feature Area 3: Quantization

### FD-006: Quantize Model for SpikeCore via TVM

- **Role:** ML Engineer / Researcher (with TVM installed)
- **Goal:** Apply int8 quantization to a Relay module, configured specifically for SpikeCore's integer-only datapath.
- **Entry:** Python API call to `quantize_for_spikecore(mod, params, calibration_dataset=None)`
- **Capability:** Wraps TVM's `relay.quantize.quantize()` with SpikeCore-specific configuration: int8 inputs, int8 weights, int16 activations (matching SpikeCore's int16 accumulator), global_scale=8.0 calibration.
- **Inputs:**
  - `mod`: float32 Relay IRModule
  - `params`: model parameters as TVM NDArrays
  - `calibration_dataset`: optional numpy array for scale estimation (currently unused, global_scale mode)
- **Outputs:** Tuple of `(quantized_mod, params)` -- the quantized IRModule and parameters
- **Constraints:** Requires TVM. Uses `opt_level=3`.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py` lines 22-53

---

### FD-007: Manually Quantize Weights (Symmetric, int8)

- **Role:** ML Engineer / Researcher
- **Goal:** Convert float32 weight tensors to int8 using symmetric quantization, without requiring TVM.
- **Entry:** Python API call to `manual_quantize_weights(weights_fp32, bits=8)`
- **Capability:** Performs symmetric quantization: `scale = max(|w|) / 127`, `q = round(w / scale)`, clamped to [-128, 127]. Handles zero-weight edge case by returning zeros with scale=1.0.
- **Inputs:**
  - `weights_fp32`: numpy float32 array of any shape
  - `bits`: quantization bit width (default 8)
- **Outputs:** Tuple of `(weights_int8: np.ndarray, scale: float, zero_point: int)` where zero_point is always 0 (symmetric)
- **Constraints:** If all weights are near-zero (abs_max < 1e-10), returns zeros with scale=1.0.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py` lines 56-78

---

### FD-008: Manually Quantize Activations (Asymmetric, unsigned int8)

- **Role:** ML Engineer / Researcher
- **Goal:** Quantize activation values (typically post-ReLU, non-negative) to unsigned int8 range.
- **Entry:** Python API call to `manual_quantize_activations(activations_fp32, bits=8)`
- **Capability:** Performs asymmetric quantization for non-negative values: `scale = max(act) / 255`, `q = round(act / scale)`, clamped to [0, 255]. Stored as int8 (values 128-255 wrap but SpikeCore handles unsigned interpretation).
- **Inputs:**
  - `activations_fp32`: numpy float32 array (assumed non-negative)
  - `bits`: bit width (default 8)
- **Outputs:** Tuple of `(activations_int8: np.ndarray, scale: float, zero_point: int)`
- **Constraints:** Assumes non-negative input (post-ReLU). Near-zero max (< 1e-10) returns zeros.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py` lines 81-104

---

## Feature Area 4: Assembly Language (ISA)

### FD-009: Assemble Text Assembly into Instructions

- **Role:** ML Engineer / Researcher
- **Goal:** Parse human-readable SpikeCore assembly text into structured `Instruction` objects for loading into the simulator.
- **Entry:** Python API call to `assemble(text)`
- **Capability:** Parses multi-line assembly text supporting five opcodes:
  - `ACC core_N weight_bank_M spike_in_[S:E]` -- weighted accumulate
  - `FIRE core_N threshold_T [shift_S]` -- threshold + spike emission (optional shift operand)
  - `LEAK core_N decay_D` -- membrane potential decay
  - `NOP` -- no operation
  - `HALT` -- stop execution
  Supports comments (lines starting with `#` or `//`), blank lines, and address-prefixed lines (e.g., `0000: ACC ...`). Case-insensitive for opcodes.
- **Inputs:** `text`: multi-line string of SpikeCore assembly
- **Outputs:** List of `Instruction` objects (dataclass with `opcode: Opcode`, `core_id: int`, `operands: tuple[int, ...]`)
- **Constraints:** Raises `ValueError` with line number on unparseable instructions. Comments and blank lines are silently skipped.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/assembly.py` lines 118-128 (assembler), lines 76-115 (parsing logic)

---

### FD-010: Disassemble Instruction Program to Text

- **Role:** ML Engineer / Researcher
- **Goal:** Convert a list of `Instruction` objects into a human-readable assembly listing for inspection and debugging.
- **Entry:** Python API call to `disassemble(program)` or `disassemble_one(inst)`
- **Capability:** Produces formatted text with address prefixes (e.g., `  0000: ACC  core_3  weight_bank_0  spike_in_[0:8]`). Each opcode has a distinct text format. Individual instructions also auto-format via their `__repr__` method.
- **Inputs:** List of `Instruction` objects (or a single instruction for `disassemble_one`)
- **Outputs:** Formatted string with one instruction per line, prefixed with 4-digit address numbers
- **Constraints:** None -- always succeeds on valid Instruction objects.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/assembly.py` lines 43-71

---

### FD-011: Assembly Round-Trip (Assemble/Disassemble)

- **Role:** ML Engineer / Researcher
- **Goal:** Verify that assembly text survives disassembly and re-assembly without data loss, enabling reliable serialization of programs.
- **Entry:** Sequential calls to `disassemble(program)` then `assemble(text)`
- **Capability:** The assembler can parse the output of the disassembler, including the `0000:` address prefixes. This enables text-based program storage and editing.
- **Inputs:** Either direction: instructions or text
- **Outputs:** Equivalent representation in the other format
- **Constraints:** FIRE shift operands of 0 are normalized (omitted in text, parsed as 0 or absent).
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py` lines 52-65 (round-trip test)

---

## Feature Area 5: Hardware Simulation

### FD-012: Initialize SpikeCore Virtual CPU

- **Role:** ML Engineer / Researcher
- **Goal:** Create a simulated SpikeCore neuromorphic processor with configurable core count for running compiled programs.
- **Entry:** Python constructor `SpikeCoreCPU(num_cores=128)`
- **Capability:** Instantiates a virtual CPU with the specified number of `NeuronCore` instances, each having an int16 accumulator, membrane potential, 256 bytes of int8 weight memory, and a spike flag. Default is 128 cores.
- **Inputs:** `num_cores`: integer (default 128)
- **Outputs:** `SpikeCoreCPU` object ready for program/weight loading
- **Constraints:** Each core has 256 bytes of local weight memory (`WEIGHT_MEM_BYTES = 256`). Total cores limited by memory.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py` lines 36-44

---

### FD-013: Load Compiled Program into Simulator

- **Role:** ML Engineer / Researcher
- **Goal:** Load a compiled SpikeCore instruction program into the virtual CPU for execution.
- **Entry:** Python API call to `cpu.load_program(program)`
- **Capability:** Stores a copy of the instruction list in the CPU, ready for `run()`.
- **Inputs:** `program`: list of `Instruction` objects
- **Outputs:** None (side effect: program stored internally)
- **Constraints:** None -- any instruction list is accepted.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py` lines 46-48

---

### FD-014: Load Quantized Weights into Simulator Cores

- **Role:** ML Engineer / Researcher
- **Goal:** Distribute int8 weight matrices across neuron cores so the simulator can perform weighted accumulations.
- **Entry:** Python API call to `cpu.load_weights(layer_id, weights_int8, core_offset=None)`
- **Capability:** Distributes rows of the weight matrix across consecutive cores. Each row's values are copied into the corresponding core's local weight memory. Supports automatic sequential core offset tracking across layers (if `core_offset=None`), or explicit offset specification.
- **Inputs:**
  - `layer_id`: integer (used in error messages)
  - `weights_int8`: numpy int8 array of shape `(out_features, in_features)`
  - `core_offset`: optional starting core index (auto-tracked if None)
- **Outputs:** None (side effect: core weight memories populated)
- **Constraints:**
  - Raises `ValueError` if required core index exceeds `num_cores`
  - Input features per core are capped at `WEIGHT_MEM_BYTES` (256)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py` lines 50-70

---

### FD-015: Execute Simulation (Run Program with Input Spikes)

- **Role:** ML Engineer / Researcher
- **Goal:** Execute the loaded SpikeCore program on input data for a specified number of timesteps, simulating event-driven neuromorphic computation.
- **Entry:** Python API call to `cpu.run(input_spikes, timesteps=1)`
- **Capability:** Runs the full instruction program for each timestep. Uses an "activation bus" for inter-layer communication with layer-aware snapshotting (same-layer ACC instructions read from the same bus snapshot, simulating parallel execution). At each timestep:
  - ACC: performs weighted dot-product from bus snapshot into core accumulator
  - FIRE: compares accumulator + membrane_potential against threshold; if exceeded, emits spike to bus (with right-shift scaling), resets accumulator/membrane; otherwise, stores total in membrane potential
  - LEAK: decays membrane potential by fixed-point factor (decay/256)
  - HALT: stops execution for that timestep
  Input spikes are re-injected at the start of each timestep. Spike events are logged as `(timestep, core_id)`.
- **Inputs:**
  - `input_spikes`: int8 numpy array representing input activations
  - `timesteps`: number of simulation timesteps (default 1)
- **Outputs:** numpy int32 array of spike counts per core over all timesteps
- **Constraints:**
  - Bus output from FIRE is clamped to int8 range [-128, 127] via right-shift and np.clip
  - All cores are reset at the start of `run()`
  - Bus size is `max(num_cores, len(input_spikes))`
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py` lines 117-177

---

### FD-016: Retrieve Spike Log History

- **Role:** ML Engineer / Researcher
- **Goal:** Access the detailed temporal record of which cores spiked at which timesteps, for analysis and visualization.
- **Entry:** Python API call to `cpu.get_spike_log()`
- **Capability:** Returns a copy of the spike event log populated during the most recent `run()` call.
- **Inputs:** None
- **Outputs:** List of `(timestep: int, core_id: int)` tuples
- **Constraints:** Log is cleared at the start of each `run()` call.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py` lines 179-181

---

### FD-017: Read Output Layer Activations from Cores

- **Role:** ML Engineer / Researcher
- **Goal:** Extract the final accumulator/membrane values from designated output cores, interpreting them as classification logits for single-timestep rate-coded inference.
- **Entry:** Python API call to `cpu.get_output_activations(output_core_ids)`
- **Capability:** For each specified core, returns `accumulator + membrane_potential` as an int32 value. These raw values serve as logits for classification tasks.
- **Inputs:** `output_core_ids`: list of integer core indices (e.g., `[64, 65, ..., 73]` for the 10-class output layer)
- **Outputs:** numpy int32 array of activation values, one per requested core
- **Constraints:** Core IDs must be valid (within `num_cores`).
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py` lines 183-193

---

## Feature Area 6: Visualization

### FD-018: Plot Spike Raster

- **Role:** ML Engineer / Researcher
- **Goal:** Visualize the temporal spiking activity of neuron cores as a raster plot (neurons on y-axis, timesteps on x-axis).
- **Entry:** Python API call to `plot_spike_raster(spike_log, num_cores=None, num_timesteps=None, title=..., figsize=..., ax=None)`
- **Capability:** Creates a scatter plot showing spike events as vertical tick marks. Auto-detects core count and timestep range from data if not specified. If no spikes exist, shows a centered "No spikes recorded" message. Supports plotting on a provided matplotlib axes (for subplot composition).
- **Inputs:**
  - `spike_log`: list of `(timestep, core_id)` tuples
  - `num_cores`, `num_timesteps`: optional bounds (auto-detected if None)
  - `title`, `figsize`, `ax`: display customization
- **Outputs:** matplotlib `Figure` object (if `ax` was None), otherwise `None`
- **Constraints:** None
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/visualize.py` lines 17-67

---

### FD-019: Plot Compilation Graph (Partitioned Layers)

- **Role:** ML Engineer / Researcher
- **Goal:** Visualize the partitioned compilation graph showing which layers are offloaded to SpikeCore vs. remaining on the host CPU.
- **Entry:** Python API call to `plot_compilation_graph(layer_names, layer_targets, layer_shapes=None, title=..., figsize=...)`
- **Capability:** Draws a horizontal sequence of colored boxes representing layers: blue (#2196F3) for "spikecore" target, gray (#9E9E9E) for "host". Arrows connect consecutive layers. Optionally shows input-to-output feature dimensions. Includes a color legend.
- **Inputs:**
  - `layer_names`: list of strings (display names per layer)
  - `layer_targets`: list of strings ("spikecore" or "host" per layer)
  - `layer_shapes`: optional list of `(in_features, out_features)` tuples
  - `title`, `figsize`: display customization
- **Outputs:** matplotlib `Figure` object
- **Constraints:** `layer_names` and `layer_targets` must be the same length.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/visualize.py` lines 70-134

---

### FD-020: Plot Quantized Weight Distribution Histogram

- **Role:** ML Engineer / Researcher
- **Goal:** Inspect the distribution of quantized int8 weight values for a given layer, to assess quantization quality.
- **Entry:** Python API call to `plot_weight_distribution(weights_int8, layer_name=..., figsize=..., ax=None)`
- **Capability:** Creates a histogram with 256 bins (one per int8 value, -128 to 127). Shows a red dashed zero-line. Includes a statistics box with mean, standard deviation, and value range. Supports subplot composition via `ax` parameter.
- **Inputs:**
  - `weights_int8`: int8 numpy array (any shape, will be flattened)
  - `layer_name`: string for title
  - `figsize`, `ax`: display customization
- **Outputs:** matplotlib `Figure` object (if `ax` was None), otherwise `None`
- **Constraints:** None
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/visualize.py` lines 137-172

---

### FD-021: Plot PyTorch vs SpikeCore Output Comparison

- **Role:** ML Engineer / Researcher
- **Goal:** Side-by-side comparison of classification outputs from the original PyTorch model and the SpikeCore-compiled version, to visually assess quantization fidelity.
- **Entry:** Python API call to `plot_comparison(pytorch_probs, spikecore_scores, class_names=None, title=..., figsize=...)`
- **Capability:** Creates two bar charts side-by-side: PyTorch softmax probabilities (left) and normalized SpikeCore scores (right). Highlights the predicted class in red for each. The figure title indicates "MATCH" (green) or "MISMATCH" (red) based on whether top-1 predictions agree.
- **Inputs:**
  - `pytorch_probs`: numpy array of softmax probabilities (e.g., shape `(10,)`)
  - `spikecore_scores`: numpy array of raw SpikeCore output scores
  - `class_names`: optional list of string labels (defaults to `["0", "1", ..., "9"]`)
  - `title`, `figsize`: display customization
- **Outputs:** matplotlib `Figure` object
- **Constraints:** Both arrays must have the same length. SpikeCore scores are normalized by sum for display.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/visualize.py` lines 175-228

---

## Feature Area 7: Interactive Notebook Pipeline

### FD-022: Run Full PyTorch-to-SpikeCore Pipeline in Jupyter Notebook

- **Role:** ML Engineer / Researcher
- **Goal:** Walk through the complete end-to-end neuromorphic compilation pipeline interactively, with visible outputs at each stage.
- **Entry:** Open and run `notebooks/01_spikecore_tvm.ipynb` (either in Docker via JupyterLab at port 8888, or locally)
- **Capability:** The notebook contains 11 executable sections (cells 2-20) covering:
  1. Setup and imports (cell 2)
  2. Train a 2-layer MLP (784->64->10) on MNIST with PyTorch (cell 4)
  3. Export model to TVM Relay IR, or display reference IR if TVM unavailable (cell 6)
  4. Quantize weights from float32 to int8, including error analysis (cell 8)
  5. Register SpikeCore BYOC target in TVM, or show reference pattern table (cell 10)
  6. Partition graph into host vs SpikeCore subgraphs, with compilation graph visualization (cell 12)
  7. Generate SpikeCore assembly, show instruction counts and first 20 lines of listing (cell 14)
  8. Simulate on SpikeCore hardware -- load weights, quantize input, run 8 timesteps, read output (cell 16)
  9. Compare PyTorch vs SpikeCore on 100 test samples with match rate and side-by-side visualization (cell 18)
  10. Multi-timestep simulation (16 timesteps) with spike raster and weight distribution plots (cell 20)
- **Inputs:** User clicks "Run All Cells" or runs cells individually
- **Outputs:** Printed metrics, assembly listings, and matplotlib visualizations at each stage
- **Constraints:**
  - Requires PyTorch and torchvision (downloads MNIST dataset on first run)
  - TVM is optional -- notebook gracefully degrades to standalone compilation path
  - Docker environment provides full TVM support; local environment uses standalone path
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/notebooks/01_spikecore_tvm.ipynb` (all cells)

---

## Feature Area 8: Docker Development Environment

### FD-023: Build Docker Container with TVM + PyTorch + Jupyter

- **Role:** ML Engineer / Researcher
- **Goal:** Build a reproducible development environment containing TVM (built from source with LLVM), PyTorch CPU, and Jupyter for running the full BYOC pipeline.
- **Entry:** Shell command `docker compose build`
- **Capability:** Multi-stage Docker build:
  1. Stage 1 (tvm-builder): Installs build tools, LLVM 15, clones TVM from GitHub, builds with CMake + Ninja using LLVM backend and Relay debug mode
  2. Stage 2 (runtime): Copies built TVM, installs Python dependencies (PyTorch CPU, numpy, matplotlib, jupyter, onnx, pytest, scipy), sets TVM environment variables
- **Inputs:** None (automated build process)
- **Outputs:** Docker image with working TVM, PyTorch, and Jupyter
- **Constraints:** Requires internet access for TVM clone and pip installs. Build is resource-intensive (TVM compilation from source).
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/Dockerfile` lines 1-63

---

### FD-024: Launch Jupyter Lab via Docker Compose

- **Role:** ML Engineer / Researcher
- **Goal:** Start the development environment with a single command, accessing Jupyter on localhost.
- **Entry:** Shell command `docker compose up`
- **Capability:** Starts the `lab` service, mapping port 8888 on the host to the container. Mounts `./notebooks`, `./spikecore`, and `./tests` directories as volumes for live editing. Launches Jupyter Notebook with token `spikecore`, accessible at `http://localhost:8888/?token=spikecore`.
- **Inputs:** None
- **Outputs:** Running Jupyter server accessible on port 8888
- **Constraints:**
  - Fixed authentication token: `spikecore`
  - `--allow-root` flag is set (container runs as root)
  - Volume mounts enable live code editing without rebuilding
  - `PYTHONDONTWRITEBYTECODE=1` prevents `.pyc` file pollution in mounted volumes
- **Evidence:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docker-compose.yml` lines 1-10
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/Dockerfile` lines 59-63

---

## Feature Area 9: Testing

### FD-025: Run Unit Test Suite

- **Role:** ML Engineer / Researcher / CI system
- **Goal:** Verify correctness of the assembly, simulator, codegen, and round-trip compilation pipeline.
- **Entry:** Shell command `pytest tests/ -v`
- **Capability:** Three test modules covering:
  - **Assembly tests** (7 tests): ACC/FIRE/LEAK/NOP/HALT parsing, comment handling, address prefix parsing, disassemble-assemble round-trip, error on bad instructions
  - **Simulator tests** (9 tests): Core initial state, reset, ACC weighted accumulation, FIRE with/without threshold exceeded, LEAK decay, two-neuron integration, output activation reading
  - **Codegen tests** (5 tests): Single-layer with ReLU, output layer without activation, two-layer MLP, MNIST-sized MLP shape, disassemble readability
  - **Round-trip tests** (4 tests): PyTorch float accuracy on synthetic data, SpikeCore-vs-PyTorch match rate >= 70%, valid assembly structure, non-empty spike log
- **Inputs:** None (self-contained with synthetic data)
- **Outputs:** Pass/fail per test with pytest output
- **Constraints:** Does not require TVM. Does not require MNIST download (uses synthetic data). Round-trip test uses 200-epoch trained numpy MLP on 4-class synthetic dataset.
- **Evidence:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py` (16 tests across 3 classes)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_codegen.py` (8 tests across 3 classes)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_roundtrip.py` (4 tests in 1 class)

---

## Feature Area 10: Library Package API

### FD-026: Import SpikeCore as a Python Package

- **Role:** ML Engineer / Researcher
- **Goal:** Access all SpikeCore capabilities through a clean top-level import.
- **Entry:** Python statement `import spikecore` or `from spikecore import ...`
- **Capability:** The `__init__.py` exports all primary user-facing symbols:
  - Hardware model: `SpikeCoreCPU`, `NeuronCore`, `Instruction`
  - Assembly: `assemble`, `disassemble`, `Opcode`
  - Codegen: `register_spikecore_target`
  - Patterns: `spikecore_pattern_table`
  - Quantization: `quantize_for_spikecore`
  - Visualization: `plot_spike_raster`, `plot_compilation_graph`, `plot_weight_distribution`
- **Inputs:** None
- **Outputs:** Available module namespace
- **Constraints:** TVM-dependent functions (`register_spikecore_target`, `spikecore_pattern_table`, `quantize_for_spikecore`) import successfully even without TVM but raise `RuntimeError` when called.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/__init__.py` lines 1-8

---

## Summary of Findings

| ID | Feature | Entry Point | TVM Required? |
|----|---------|-------------|---------------|
| FD-001 | Compile from PyTorch state_dict | `compile_from_torch()` | No |
| FD-002 | Compile from weight/bias arrays | `compile_nn_to_spikecore()` | No |
| FD-003 | Register BYOC target | `register_spikecore_target()` | Yes |
| FD-004 | Partition Relay graph | `partition_for_spikecore()` | Yes |
| FD-005 | Pattern table for MergeComposite | `spikecore_pattern_table()` | Yes |
| FD-006 | TVM quantization for SpikeCore | `quantize_for_spikecore()` | Yes |
| FD-007 | Manual weight quantization | `manual_quantize_weights()` | No |
| FD-008 | Manual activation quantization | `manual_quantize_activations()` | No |
| FD-009 | Assemble text to instructions | `assemble()` | No |
| FD-010 | Disassemble instructions to text | `disassemble()` | No |
| FD-011 | Assembly round-trip | `assemble()` + `disassemble()` | No |
| FD-012 | Initialize virtual CPU | `SpikeCoreCPU()` | No |
| FD-013 | Load program into simulator | `cpu.load_program()` | No |
| FD-014 | Load weights into simulator | `cpu.load_weights()` | No |
| FD-015 | Execute simulation | `cpu.run()` | No |
| FD-016 | Retrieve spike log | `cpu.get_spike_log()` | No |
| FD-017 | Read output activations | `cpu.get_output_activations()` | No |
| FD-018 | Plot spike raster | `plot_spike_raster()` | No |
| FD-019 | Plot compilation graph | `plot_compilation_graph()` | No |
| FD-020 | Plot weight distribution | `plot_weight_distribution()` | No |
| FD-021 | Plot PyTorch vs SpikeCore comparison | `plot_comparison()` | No |
| FD-022 | Interactive notebook pipeline | Jupyter notebook | No (degrades gracefully) |
| FD-023 | Build Docker environment | `docker compose build` | N/A (builds TVM) |
| FD-024 | Launch Jupyter via Docker | `docker compose up` | N/A |
| FD-025 | Run test suite | `pytest tests/ -v` | No |
| FD-026 | Import package | `import spikecore` | No (deferred errors) |

### Key Architectural Insight

The system is deliberately designed with **dual execution paths**: 18 of the 26 features work entirely without TVM, while 5 features (FD-003 through FD-006, and FD-005) require TVM. This design decision (documented in the design doc at FD-023's evidence file) ensures the core compilation, simulation, and visualization workflow is accessible without the heavyweight TVM dependency, while the Docker environment provides the full BYOC pipeline for those who need it. The notebook (FD-022) gracefully detects TVM availability and switches between paths automatically.

## Domain Analyst Report

# Domain Analysis Report: SpikeCore Lab

## Executive Summary

SpikeCore Lab models the domain of **neuromorphic compilation** -- the transformation of conventional neural network models into programs executable on brain-inspired hardware. The system encodes knowledge about three interconnected domain areas: (1) a neuromorphic hardware architecture with spiking neuron semantics, (2) a compilation pipeline that bridges floating-point ML models to integer-only neuromorphic assembly, and (3) a quantization discipline that maps continuous values to discrete hardware-compatible representations. The domain vocabulary closely mirrors Intel's Loihi/Lava ecosystem, establishing SpikeCore as a didactic proxy for real neuromorphic targets.

---

## Domain Area 1: Neuromorphic Hardware Architecture

### DA-001: Entity: NeuronCore
- **Purpose:** Represents a single computational unit on the neuromorphic chip, modeling a biological neuron with local state and local synaptic storage. Each core independently accumulates weighted inputs, maintains membrane potential across timesteps, and emits spikes when a threshold is exceeded.
- **Attributes:**
  - `core_id: int` -- Unique identifier for the core within the chip (0 to NUM_CORES-1)
  - `accumulator: int` (default 0) -- Current weighted sum of inputs for the active computation cycle; represents dendritic accumulation
  - `membrane_potential: int` (default 0) -- Persistent state that carries over across timesteps when the core does not fire; models the biological membrane voltage
  - `weights: np.ndarray` (int8, 256 bytes) -- Local synaptic weight storage; each core has exactly WEIGHT_MEM_BYTES (256) bytes of int8 weight memory, representing the synaptic strengths of connections to input neurons
  - `has_spiked: bool` (default False) -- Transient flag indicating whether the core emitted a spike in the current timestep
- **Relationships:** Belongs to exactly one SpikeCoreCPU. Multiple NeuronCores compose a chip. Cores communicate indirectly via the activation bus (not direct core-to-core connections).
- **Rules:**
  - Weight memory is capped at 256 bytes per core (WEIGHT_MEM_BYTES constant)
  - Weights must be int8 dtype -- the hardware only supports integer arithmetic
  - Reset clears accumulator, membrane_potential, and has_spiked to zero/False
- **Lifecycle:** Active -> Accumulating (ACC instruction received) -> Evaluating (FIRE instruction) -> either Spiked (threshold exceeded, accumulator and membrane reset to 0) or Subthreshold (membrane absorbs total, accumulator resets to 0). LEAK instruction decays membrane potential independently.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:20-33`

### DA-002: Entity: SpikeCoreCPU
- **Purpose:** The top-level hardware simulator representing the entire neuromorphic chip. It orchestrates program execution, weight distribution across cores, spike logging, and inter-layer communication via a shared activation bus.
- **Attributes:**
  - `num_cores: int` (default 128) -- Total number of neuron cores on chip
  - `cores: list[NeuronCore]` -- Array of all neuron cores
  - `program: list[Instruction]` -- The currently loaded assembly program
  - `spike_log: list[tuple[int, int]]` -- Temporal spike history as (timestep, core_id) pairs; the fundamental observability mechanism
  - `_next_core_offset: int` -- Cumulative tracking for sequential weight loading across layers
- **Relationships:** Composes NeuronCores. Executes Instructions. Produces spike logs consumed by visualization.
- **Rules:**
  - Core count is fixed at construction time (default NUM_CORES = 128)
  - Weight loading must not exceed available cores (raises ValueError with diagnostic message mentioning layer_id)
  - Weight matrix rows map 1:1 to cores (one output neuron per core)
  - If weight row width exceeds WEIGHT_MEM_BYTES, it is silently truncated to fit
  - Layer-aware snapshotting: within a layer, all ACC instructions read from the same bus snapshot, simulating parallel hardware execution; when the ACC input range changes (new layer boundary), the snapshot refreshes
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:36-194`

### DA-003: Entity: Activation Bus
- **Purpose:** The shared inter-core communication channel. Not a formal entity but an implicit domain concept -- a chip-wide int16 array through which spikes (output activations) propagate from one layer's cores to the next layer's inputs. Models the biological axonal bus.
- **Attributes:**
  - Size: `max(num_cores, len(input_spikes))` -- dynamically sized
  - Dtype: int16 -- the bus carries int16 values, wider than int8 weights to accommodate partial accumulation results
- **Rules:**
  - Input spikes are injected at the start of each timestep (positions 0 through len(input_spikes)-1)
  - FIRE instruction writes clamped-to-int8 values onto the bus at the core's own index position
  - Bus is zeroed and re-injected with input at each timestep boundary
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:140-148`

### DA-004: Constants: Hardware Specification
- **Purpose:** Define the physical constraints of the SpikeCore chip architecture.
- **Attributes:**
  - `NUM_CORES = 128` -- Total neuron cores per chip
  - `WEIGHT_MEM_BYTES = 256` -- Bytes of local weight storage per core
- **Rules:** These constants establish hard limits that the compiler and weight-loading logic must respect. Any neural network layer with more output neurons than available cores cannot be mapped to a single chip.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:16-17`

---

## Domain Area 2: Instruction Set Architecture (ISA)

### DA-005: Entity: Opcode (Enumeration)
- **Purpose:** Defines the complete instruction vocabulary of the SpikeCore ISA. Five opcodes model the core operations of neuromorphic computation plus flow control.
- **Values:**
  - `ACC = 0` -- Weighted accumulate: performs dot product of input spike slice against local weight slice, adding result to the core's accumulator. Maps to dendritic/synaptic integration in neuroscience.
  - `FIRE = 1` -- Threshold-based spike emission: if (accumulator + membrane_potential) >= threshold, emit a scaled spike, reset state. Maps to axonal spike generation.
  - `LEAK = 2` -- Membrane potential decay: multiplies membrane_potential by (decay/256) using fixed-point arithmetic. Models biological leak currents that cause inactive neurons to gradually return to resting potential.
  - `NOP = 3` -- No operation: pipeline bubble, no side effects.
  - `HALT = 4` -- Terminates program execution.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/assembly.py:23-28`

### DA-006: Entity: Instruction
- **Purpose:** A single machine instruction for the SpikeCore processor. Immutable (frozen dataclass) value object encoding one operation.
- **Attributes:**
  - `opcode: Opcode` -- Which operation to perform
  - `core_id: int` (default 0) -- Target neuron core
  - `operands: tuple[int, ...]` (default empty) -- Variable-length operand tuple, interpreted differently per opcode:
    - ACC operands: `(weight_bank, input_start, input_end)` -- which weight bank and which slice of the activation bus to read
    - FIRE operands: `(threshold,)` or `(threshold, shift)` -- threshold for spike emission and optional right-shift for rescaling accumulator to int8
    - LEAK operands: `(decay,)` -- fixed-point decay factor (0-255, representing decay/256)
    - NOP/HALT: no operands
- **Relationships:** Instructions compose into programs (ordered lists). Each Instruction targets exactly one NeuronCore.
- **Rules:**
  - Instruction is frozen (immutable value object)
  - FIRE shift parameter controls output rescaling: `scaled = total >> shift` to fit accumulator-wide values back into int8 bus range
  - LEAK decay is fixed-point: actual decay factor = decay/256 (so decay=240 means ~93.75% retention, decay=128 means 50%)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/assembly.py:31-37`

### DA-007: Business Rule: ACC Instruction Execution Semantics
- **Description:** The ACC instruction performs a weighted dot product between a slice of the activation bus and the core's local weights, accumulating the result in int32 arithmetic.
- **Applies To:** NeuronCore, Activation Bus
- **Condition:** When an ACC instruction is executed during simulation
- **Enforcement:** `spike_slice = bus[start:actual_end].astype(np.int32)`, `weight_slice = core.weights[:n].astype(np.int32)`, result is `int(np.sum(spike_slice * weight_slice))` added to `core.accumulator`. The end index is clamped to actual bus length to prevent out-of-bounds. Int32 arithmetic prevents overflow during accumulation.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:72-84`

### DA-008: Business Rule: FIRE Instruction -- Threshold-and-Reset Neuron Model
- **Description:** The FIRE instruction implements the Integrate-and-Fire neuron model: if the combined accumulator + membrane_potential exceeds a threshold, the neuron spikes and resets; otherwise, the total is stored in membrane_potential for the next timestep.
- **Applies To:** NeuronCore, Activation Bus
- **Condition:** When a FIRE instruction is executed
- **Enforcement:**
  - `total = core.accumulator + core.membrane_potential`
  - If `total >= threshold`: spike (set `has_spiked=True`), right-shift by `shift` bits, clamp to [-128, 127], write to bus at `core_id`, reset both accumulator and membrane_potential to 0
  - If `total < threshold`: no spike, `membrane_potential = total`, `accumulator = 0`, `has_spiked = False`
  - The shift parameter enables inter-layer rescaling: `shift = ceil(log2(fan_in)) + 7` normalizes the wide accumulator output back to int8 range
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:86-108`

### DA-009: Business Rule: LEAK Instruction -- Fixed-Point Membrane Decay
- **Description:** The LEAK instruction decays the membrane potential using fixed-point multiplication, modeling biological leak currents that cause membrane voltage to drift toward resting potential over time.
- **Applies To:** NeuronCore
- **Condition:** When a LEAK instruction is executed
- **Enforcement:** `leaked = (core.membrane_potential * decay) >> 8` -- this is equivalent to multiplying by `decay/256`. A decay of 240 retains 93.75%; a decay of 128 retains 50%.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:110-115`

### DA-010: Business Rule: Layer-Aware Snapshotting for Parallel Semantics
- **Description:** To simulate parallel hardware execution within a single layer, the simulator snapshots the activation bus at layer boundaries. All ACC instructions within the same layer read from the same snapshot, preventing early-firing cores from corrupting the input seen by later cores in the same layer.
- **Applies To:** SpikeCoreCPU execution loop
- **Condition:** During program execution, whenever ACC's input range changes (indicating a new layer boundary)
- **Enforcement:** `if acc_range != last_acc_range: snapshot = bus.copy()` -- a fresh snapshot is taken each time the ACC operands indicate a different input slice (i.e., a new layer). This range-based heuristic determines layer boundaries.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:150-162`

---

## Domain Area 3: Assembly Language (Assembler/Disassembler)

### DA-011: Business Rule: Assembly Text Format Specification
- **Description:** SpikeCore defines a human-readable assembly language with strict formatting conventions that enable round-trip assembly/disassembly.
- **Applies To:** All Instruction types
- **Condition:** When converting between text and binary instruction representations
- **Enforcement:**
  - ACC format: `ACC  core_{id}  weight_bank_{bank}  spike_in_[{start}:{end}]`
  - FIRE format: `FIRE core_{id}  threshold_{value}` with optional `shift_{value}`
  - LEAK format: `LEAK core_{id}  decay_{value}`
  - NOP: bare `NOP`
  - HALT: bare `HALT`
  - Comments supported: lines starting with `#` or `//` are ignored
  - Address prefix stripping: lines with `NNNN:` prefix (disassembler output format) can be reassembled
  - Parsing is case-insensitive for opcodes
  - Invalid instructions raise `ValueError` with line number context
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/assembly.py:43-128`

### DA-012: Business Rule: Assembly Round-Trip Fidelity
- **Description:** Any program that is disassembled and then reassembled must produce semantically identical instructions (same opcodes, core_ids, and operands).
- **Applies To:** assemble() and disassemble() functions
- **Enforcement:** Tested explicitly in `test_roundtrip_disassemble_assemble` which verifies opcode, core_id, and operands match after a full round-trip.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:52-66`

---

## Domain Area 4: Compilation Pipeline

### DA-013: Entity: Relay Pattern (Composite Pattern Mapping)
- **Purpose:** Defines the mapping between TVM Relay IR subgraph patterns and SpikeCore hardware primitives. Each pattern represents a fuseable cluster of operations that can be offloaded to the neuromorphic accelerator.
- **Attributes (3 patterns):**
  - `spikecore.dense_relu` -- Matches `nn.dense(x, w) -> bias_add -> relu`. Maps to ACC + FIRE (hidden layer with activation). This is the float pre-quantization path.
  - `spikecore.dense_bias` -- Matches `nn.dense(x, w) -> bias_add`. Maps to ACC only (output layer, no activation function).
  - `spikecore.qnn_dense_clip` -- Matches `qnn.dense -> add -> clip(0, 127)`. Maps to ACC + FIRE (quantized integer path).
- **Relationships:** Consumed by TVM's `relay.transform.MergeComposite` pass. Each pattern requires specific constants (weights, biases, zero points, scales).
- **Rules:**
  - Pattern matching uses TVM's dataflow pattern (DFPattern) API
  - Patterns are ordered: more specific patterns should appear earlier to get priority (qnn_dense_clip before dense_relu)
  - TVM must be available for pattern table generation (RuntimeError raised otherwise)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/relay_patterns.py:1-78`

### DA-014: Entity: Layer Configuration (Compilation Input)
- **Purpose:** Describes one neural network layer for the standalone (non-TVM) compilation path. Used by `compile_from_torch` to generate SpikeCore assembly without requiring TVM infrastructure.
- **Attributes:**
  - `name: str` -- Layer name prefix, used to look up weights in the state_dict (e.g., "layers.0")
  - `in_features: int` -- Input dimension (fan-in), used to compute ACC input range and FIRE shift
  - `out_features: int` -- Output dimension, determines how many cores this layer occupies
  - `activation: str | None` -- Either "relu" (generates FIRE + LEAK instructions) or None (ACC only, for output layers)
- **Relationships:** Used by compile_from_torch alongside a state_dict. One LayerConfig per neural network layer.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py:155-215`

### DA-015: Business Rule: Core Allocation Strategy
- **Description:** Each output neuron in a neural network layer is mapped to exactly one SpikeCore neuron core. Cores are allocated sequentially across layers, with a running offset. This means a 2-layer MLP with shapes 64 and 10 uses cores 0-63 for layer 1 and cores 64-73 for layer 2.
- **Applies To:** compile_from_torch, compile_nn_to_spikecore, SpikeCoreCPU.load_weights
- **Condition:** During compilation and weight loading
- **Enforcement:** `core_offset` starts at 0 and increments by `out_features` after each layer. In `compile_from_torch`: `core_id = core_offset + i` for each output neuron. In `load_weights`: `self._next_core_offset = core_offset + out_features` tracks cumulative allocation. Verified in test: `acc_cores == list(range(8)) + list(range(8, 11))` for an 8+3 neuron network.
- **Evidence:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py:179-212`
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:50-70`
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_codegen.py:82-83`

### DA-016: Business Rule: Instruction Generation Pattern per Layer Type
- **Description:** The compiler generates a deterministic pattern of instructions depending on whether a layer has an activation function.
- **Applies To:** compile_from_torch, compile_nn_to_spikecore
- **Condition:** For each output neuron in each layer
- **Enforcement:**
  - **Hidden layer (activation="relu"):** Generates `ACC(core_id, (0, 0, in_features))` + `FIRE(core_id, (0, shift))` + `LEAK(core_id, (240,))` -- three instructions per neuron
  - **Output layer (activation=None):** Generates only `ACC(core_id, (0, 0, in_features))` -- one instruction per neuron
  - Final instruction is always `HALT`
  - FIRE threshold is always 0 for the standalone path (all positive accumulations fire)
  - LEAK decay is always 240 (hardcoded ~93.75% retention)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py:196-214`

### DA-017: Business Rule: FIRE Shift Computation
- **Description:** The right-shift applied in the FIRE instruction must rescale the accumulator output (which can be very large from summing many int8*int8 products) back to int8 range for downstream consumption. The formula is `shift = ceil(log2(fan_in)) + 7`.
- **Applies To:** FIRE instructions in compiled programs
- **Condition:** At compile time, based on the layer's fan-in (input features)
- **Enforcement:** `_compute_fire_shift(fan_in)` computes the shift. The maximum accumulator value is approximately `fan_in * 127 * 127`. The 7 accounts for the 127*127 = 16129 factor (approximately 2^14, but the formula uses 7 for the 127 factor on each side). For fan_in=1, shift=7 (just the int8*int8 -> int8 scaling). For fan_in=784 (MNIST), shift = ceil(log2(784)) + 7 = 10 + 7 = 17.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py:26-37`

### DA-018: Business Rule: BYOC Pipeline Sequence
- **Description:** TVM graph compilation for SpikeCore follows a fixed three-pass sequence: MergeComposite (fuse ops into patterns) -> AnnotateTarget (mark for offloading) -> PartitionGraph (split host vs. accelerator subgraphs).
- **Applies To:** partition_for_spikecore function
- **Condition:** When TVM is available and the full BYOC path is used
- **Enforcement:** `tvm.transform.Sequential([relay.transform.MergeComposite(patterns), relay.transform.AnnotateTarget(["spikecore"]), relay.transform.PartitionGraph()])` -- these passes must run in this exact order within a PassContext at opt_level=3. Parameters must be bound first via `bind_params_by_name`.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py:117-148`

### DA-019: Business Rule: Dual Execution Paths
- **Description:** The system supports two compilation paths that produce equivalent SpikeCore assembly: (1) TVM BYOC path (inside Docker, using full Relay IR transformation pipeline) and (2) Standalone path (no TVM required, using manual quantization and direct code generation). Both paths share the same simulator.
- **Applies To:** The entire compilation pipeline
- **Condition:** Determined by HAS_TVM flag (whether TVM can be imported)
- **Enforcement:** HAS_TVM is checked at module import time via try/except ImportError. Functions requiring TVM raise RuntimeError with "TVM is required" messages. Standalone functions (compile_from_torch, compile_nn_to_spikecore, manual_quantize_*) have no TVM dependency.
- **Evidence:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py:39-48` (TVM detection)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py:155-259` (standalone path)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/relay_patterns.py:13-26` (TVM detection)

### DA-020: Business Rule: Cost Estimator Always Prefers Offloading
- **Description:** The BYOC cost estimator for SpikeCore always returns 1, meaning it always prefers offloading operations to SpikeCore over keeping them on the host. This is a simplification -- a real target would estimate energy/latency.
- **Applies To:** TVM BYOC target registration
- **Enforcement:** `@tvm.register_func("relay.ext.spikecore.cost_estimator")` returns constant `1`.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py:112-114`

---

## Domain Area 5: Quantization

### DA-021: Entity: Quantization Configuration
- **Purpose:** Defines how floating-point values from the ML framework are mapped to the integer-only SpikeCore hardware. Two quantization strategies exist: TVM-managed and manual.
- **Attributes (TVM path):**
  - `nbit_input = 8` -- 8-bit inputs
  - `nbit_weight = 8` -- 8-bit weights
  - `nbit_activation = 16` -- 16-bit activations (matching SpikeCore's int16 accumulator width)
  - `dtype_input = "int8"`, `dtype_weight = "int8"`, `dtype_activation = "int16"`
  - `calibrate_mode = "global_scale"` with `global_scale = 8.0`
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py:40-52`

### DA-022: Business Rule: Symmetric Weight Quantization
- **Description:** Weights are quantized using symmetric quantization: `q = round(w / scale)` where `scale = max(|w|) / 127`. Zero point is always 0. This ensures the int8 range [-127, 127] is used symmetrically around zero.
- **Applies To:** manual_quantize_weights function
- **Condition:** For all weight tensors in the standalone compilation path
- **Enforcement:**
  - `qmax = 127` for 8-bit
  - `scale = abs_max / qmax`
  - `quantized = np.clip(np.round(weights / scale), -128, 127).astype(np.int8)`
  - Special case: if `abs_max < 1e-10`, returns zeros with scale=1.0 (avoids division by zero)
  - Zero point is always 0 (symmetric quantization)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py:56-78`

### DA-023: Business Rule: Asymmetric Activation Quantization
- **Description:** Activations (post-ReLU, non-negative) use asymmetric quantization with `qmax = 255` for unsigned 8-bit range. The zero point is 0 because ReLU outputs are always non-negative.
- **Applies To:** manual_quantize_activations function
- **Condition:** When quantizing activation tensors (assumed non-negative, post-ReLU)
- **Enforcement:**
  - `qmax = 255` (full unsigned 8-bit range)
  - `scale = act_max / qmax`
  - Values are clipped to [0, 255] then stored as int8 (values 128-255 wrap but "SpikeCore handles unsigned" per comment)
  - Special case: if `act_max < 1e-10`, returns zeros
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py:81-104`

### DA-024: Business Rule: Quantization Accuracy Threshold
- **Description:** The round-trip pipeline requires that SpikeCore's quantized predictions match PyTorch's floating-point predictions on at least 70% of test samples (top-1 agreement). This threshold acknowledges that quantization introduces error but demands the majority of predictions remain correct.
- **Applies To:** TestRoundTrip.test_spikecore_matches_pytorch
- **Condition:** When comparing quantized SpikeCore output vs. float32 PyTorch output on synthetic test data
- **Enforcement:** `assert match_rate >= 0.70` with descriptive failure message. The design document mentions targeting >=90% on MNIST; the 70% threshold applies to synthetic data with fewer features.
- **Evidence:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_roundtrip.py:145-179`
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md:68`

---

## Domain Area 6: Simulation Execution Model

### DA-025: Business Rule: Event-Driven Timestep Execution
- **Description:** The simulator executes programs in discrete timesteps. Within each timestep, all instructions execute sequentially. Between timesteps, the bus is cleared and input is re-injected. Spikes from the previous timestep are not carried forward (each timestep starts fresh from the original input).
- **Applies To:** SpikeCoreCPU.run()
- **Condition:** When running simulation with timesteps > 1
- **Enforcement:** At each timestep `t > 0`: `bus[:] = 0` then `bus[:len(input_spikes)] = input_spikes`. Spike logging records `(timestep, core_id)` pairs. Spike counts accumulate across timesteps. Core state (membrane_potential) persists across timesteps only if FIRE did not trigger (subthreshold carries over via membrane_potential).
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:117-177`

### DA-026: Business Rule: Output Activation Readout
- **Description:** For single-timestep rate-coded inference, the output layer's results are read by combining accumulator and membrane_potential from designated output cores. This serves as the logits equivalent in the neuromorphic domain.
- **Applies To:** SpikeCoreCPU.get_output_activations()
- **Condition:** After simulation completes, to read classification results
- **Enforcement:** `accumulator + membrane_potential` for each specified output core ID. Returns int32 array. The caller must know which core IDs correspond to the output layer (determined by the core allocation strategy).
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:183-193`

### DA-027: Business Rule: FIRE Output Clamping to int8
- **Description:** When a core fires, the output value written to the bus is clamped to the int8 range [-128, 127] after right-shifting. This ensures downstream layers always receive int8-compatible values regardless of how large the accumulator grew.
- **Applies To:** SpikeCoreCPU._exec_fire()
- **Condition:** When a core's total exceeds the threshold
- **Enforcement:** `bus[inst.core_id] = int(np.clip(scaled, -128, 127))` -- explicit clamping after shift. Additionally guards against writing outside bus bounds: `if inst.core_id < len(bus)`.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:99-102`

---

## Domain Area 7: Visualization and Observability

### DA-028: Entity: Spike Raster
- **Purpose:** A temporal visualization of neural activity showing which cores fire at which timesteps. This is the primary observability tool for neuromorphic systems, analogous to oscilloscope traces in electrical engineering.
- **Attributes:**
  - Input: `spike_log: list[tuple[int, int]]` -- (timestep, core_id) pairs
  - X-axis: timesteps
  - Y-axis: neuron core IDs (inverted, core 0 at top)
  - Markers: black vertical ticks at spike events
- **Relationships:** Consumes spike_log from SpikeCoreCPU.get_spike_log(). Handles empty logs with "No spikes recorded" message.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/visualize.py:17-67`

### DA-029: Entity: Compilation Graph Visualization
- **Purpose:** Shows the partitioned compilation graph as a sequence of colored boxes, distinguishing SpikeCore-offloaded operations (blue) from host CPU operations (gray). Directly visualizes the result of the BYOC partitioning pass.
- **Attributes:**
  - `layer_names: list[str]` -- operation/layer names
  - `layer_targets: list[str]` -- "spikecore" or "host" per layer
  - `layer_shapes: list[tuple[int, int]]` -- optional (in_features, out_features) annotation
  - Color coding: `spikecore = #2196F3` (blue), `host = #9E9E9E` (gray)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/visualize.py:70-134`

### DA-030: Entity: Weight Distribution Histogram
- **Purpose:** Visualizes the distribution of quantized int8 weight values, showing how the quantization process maps continuous weights to discrete integers. Includes statistics (mean, std, range).
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/visualize.py:137-172`

### DA-031: Entity: PyTorch vs. SpikeCore Comparison Plot
- **Purpose:** Side-by-side bar chart comparing PyTorch softmax probabilities against SpikeCore normalized output scores. Highlights prediction match/mismatch with color coding (green for MATCH, red for MISMATCH). This is the key verification artifact for the compilation pipeline.
- **Attributes:**
  - `pytorch_probs: np.ndarray` -- Softmax probabilities (10 classes for MNIST)
  - `spikecore_scores: np.ndarray` -- Raw output scores (normalized by sum for display)
  - Predicted class highlighted in red, other classes in blue
  - Title includes MATCH/MISMATCH verdict
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/visualize.py:175-228`

---

## Domain Area 8: Neural Network Model (Compilation Input)

### DA-032: Entity: MNISTNet (PyTorch Model)
- **Purpose:** The reference neural network that serves as the compilation input. A minimal 2-layer MLP for MNIST digit classification: 784 inputs (28x28 pixels) -> 64 hidden neurons with ReLU -> 10 output neurons (digits 0-9).
- **Attributes:**
  - Layer 1: `nn.Linear(784, 64)` + `nn.ReLU()` -- 50,240 weights + 64 biases
  - Layer 2: `nn.Linear(64, 10)` -- 640 weights + 10 biases
  - Total parameters: ~50,954
  - Input: (1, 1, 28, 28) tensor, flattened to 784
  - Output: 10 logits
- **Relationships:** State dict is extracted as numpy arrays for the standalone compilation path. Model is traced via `torch.jit.trace` for the TVM path.
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/notebooks/01_spikecore_tvm.ipynb` (Cell 4)

### DA-033: Business Rule: Model Constraints for SpikeCore Targeting
- **Description:** Only specific layer types are supported for SpikeCore offloading: dense (fully-connected) layers with optional ReLU activation and optional bias. Operations like flatten/reshape remain on the host CPU. This means: (a) total output neurons across all layers must not exceed 128, (b) input features per layer must not exceed 256 (weight memory limit), and (c) only dense+relu and dense+bias patterns are recognized.
- **Applies To:** The compilation pipeline
- **Evidence:**
  - Core limit: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:64-66`
  - Weight memory limit: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:68-69`
  - Supported patterns: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/relay_patterns.py:74-78`

---

## Domain Vocabulary Glossary

| Term | Domain Meaning | Code Location |
|------|---------------|---------------|
| **Neuron Core** | A single computational unit with local weights, accumulator, and membrane state; models one biological neuron | `hardware_model.py:21` |
| **Spike** | A discrete event emitted when a core's potential exceeds a threshold; the fundamental unit of neuromorphic communication | `hardware_model.py:98` |
| **Membrane Potential** | Persistent voltage state of a neuron that accumulates sub-threshold inputs across timesteps | `hardware_model.py:26` |
| **Accumulator** | Temporary register holding the current cycle's weighted input sum | `hardware_model.py:25` |
| **Activation Bus** | Shared communication channel carrying int16 values between layers | `hardware_model.py:141` |
| **Weight Bank** | A logical grouping of weights within a core's local memory | `assembly.py:48` |
| **Threshold** | The activation level above which a neuron fires a spike | `hardware_model.py:97` |
| **Leak/Decay** | The gradual reduction of membrane potential over time when no spike occurs | `hardware_model.py:114` |
| **Fan-in** | Number of input connections to a neuron (determines accumulator range and FIRE shift) | `byoc_codegen.py:29` |
| **BYOC** | Bring Your Own Codegen -- TVM's extensibility mechanism for custom hardware targets | `byoc_codegen.py:1` |
| **Composite Pattern** | A fused subgraph of Relay operations that maps to a SpikeCore primitive sequence | `relay_patterns.py:65` |
| **Graph Partitioning** | Splitting a computation graph into host-executed and accelerator-offloaded subgraphs | `byoc_codegen.py:117` |
| **Rate Coding** | Encoding information in spike counts (firing rates) rather than spike timing | `hardware_model.py:187` |
| **Spike Raster** | A temporal plot of spike events (neuron x timestep), the standard neuromorphic visualization | `visualize.py:17` |
| **Symmetric Quantization** | Mapping float values to int8 with zero_point=0, preserving symmetry around zero | `quantize.py:62` |

---

## Domain Relationship Map

```
MNISTNet (PyTorch)
    |
    | [export/trace]
    v
Relay IR (TVM)                          State Dict (numpy)
    |                                        |
    | [quantize_for_spikecore]               | [manual_quantize_weights]
    v                                        v
Quantized Relay IR                      Quantized Weights (int8, scale)
    |                                        |
    | [MergeComposite + AnnotateTarget       | [compile_from_torch /
    |  + PartitionGraph]                     |  compile_nn_to_spikecore]
    v                                        v
Partitioned Graph ----+              Program: list[Instruction]
    |                 |                      |
    | [BYOC codegen]  |                      |
    v                 v                      v
SpikeCore Assembly Text          SpikeCoreCPU.load_program()
    |                                        |
    | [assemble()]                           | + load_weights()
    v                                        v
list[Instruction] -----------------> SpikeCoreCPU.run()
                                             |
                                             v
                                     spike_log + spike_counts
                                     + output_activations
                                             |
                                             v
                                     Visualizations (raster, comparison)
```

Key cardinalities:
- 1 SpikeCoreCPU : N NeuronCores (N=128 default)
- 1 NeuronCore : 1 weight array (256 bytes max)
- 1 Program : M Instructions (M varies by network size)
- 1 Instruction : 1 NeuronCore target (via core_id)
- 1 Neural Network Layer : K NeuronCores (K = out_features)
- 1 Simulation Run : P Spike Events (P depends on input and weights)

---

## Key Domain Insights

1. **The domain bridges two worlds.** The system encodes knowledge from both the ML/deep learning domain (layers, activations, quantization, logits) and the neuromorphic computing domain (spikes, membrane potentials, leak currents, threshold firing). The compilation pipeline is the translator between these conceptual frameworks.

2. **Hardware constraints shape the domain model.** The 128-core limit, 256-byte weight memory, and int8/int16/int32 arithmetic precision are not arbitrary -- they model real physical constraints of neuromorphic chips (specifically analogous to Intel Loihi's neurocore architecture). Every compilation decision (core allocation, FIRE shift computation, quantization parameters) exists to respect these constraints.

3. **The Integrate-and-Fire neuron model is the fundamental abstraction.** The ACC-FIRE-LEAK instruction triple maps directly to the LIF (Leaky Integrate-and-Fire) neuron model from computational neuroscience: accumulate (synaptic integration), fire (spike generation with reset), leak (membrane decay). This is the core domain concept that everything else serves.

4. **Temporal dynamics are modeled but underutilized.** The hardware model supports multi-timestep execution with membrane potential persistence, membrane decay, and spike timing -- but the primary inference mode is single-timestep rate coding. This suggests the architecture is designed for future spike-timing-dependent features (STDP, temporal coding) mentioned in the Phase 2 roadmap.

5. **The "fictional" qualifier is strategic.** SpikeCore is explicitly fictional but closely mirrors Intel Loihi's architecture. The README maps every SpikeCore concept to its Loihi equivalent. This design choice allows demonstrating real compilation techniques without requiring access to proprietary hardware documentation.

## Behavior Analyst Report

# Behavior Analysis Report

## Test Landscape Overview

- **Frameworks:** pytest 8.3.3 (specified in `requirements.txt`); compiled `.pyc` files show `pytest-9.0.2` was actually used at runtime
- **Test Count:** 22 test functions across 3 test files and 6 test classes
- **Test Types:** Unit tests (assembly, neuron core, quantization), integration tests (SpikeCoreCPU multi-instruction programs, two-neuron network), end-to-end round-trip tests (train MLP -> compile -> verify)
- **Organization:** Tests reside in `/tests/` directory, organized by subsystem: `test_simulator.py` (assembly + hardware model), `test_codegen.py` (quantization + code generation), `test_roundtrip.py` (full pipeline)
- **Test Helpers/Fixtures:** One pytest fixture (`trained_model`) in `test_roundtrip.py`; helper functions `_make_synthetic_data`, `_train_numpy_mlp`, `_pytorch_predict`, `_spikecore_predict` provide test infrastructure without any external data dependencies (no MNIST download needed)
- **Coverage Configuration:** None configured. No `pytest.ini`, `pyproject.toml`, `setup.cfg`, or `conftest.py` found.
- **CI:** Docker-based (`Dockerfile` + `docker-compose.yml`), but no GitHub Actions or CI pipeline configuration found.

---

## Verified Behaviors

### Assembly / Instruction Set Architecture

#### BA-001: ACC Instruction Parsing
- **Level:** VERIFIED
- **Given:** Text string `"ACC core_3 weight_bank_0 spike_in_[0:8]"`
- **When:** `assemble()` is called
- **Then:** Produces exactly 1 `Instruction` with `opcode=Opcode.ACC`, `core_id=3`, `operands=(0, 0, 8)` (bank, start, end)
- **Edge Cases:** None tested for ACC specifically
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:13-18` (`TestAssembly.test_assemble_acc`)

#### BA-002: FIRE Instruction Parsing
- **Level:** VERIFIED
- **Given:** Text string `"FIRE core_5 threshold_64"`
- **When:** `assemble()` is called
- **Then:** Produces 1 `Instruction` with `opcode=Opcode.FIRE`, `core_id=5`, `operands=(64,)`
- **Edge Cases:** The optional `shift_N` operand in FIRE is recognized by the regex `_RE_FIRE` in `assembly.py:80` but is NOT tested via any assemble test
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:20-25` (`TestAssembly.test_assemble_fire`)

#### BA-003: LEAK Instruction Parsing
- **Level:** VERIFIED
- **Given:** Text string `"LEAK core_0 decay_240"`
- **When:** `assemble()` is called
- **Then:** Produces 1 `Instruction` with `opcode=Opcode.LEAK`, `core_id=0`, `operands=(240,)`
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:27-32` (`TestAssembly.test_assemble_leak`)

#### BA-004: NOP and HALT Instruction Parsing
- **Level:** VERIFIED
- **Given:** Multi-line text `"NOP\nHALT"`
- **When:** `assemble()` is called
- **Then:** Produces 2 instructions: `NOP` followed by `HALT`; both have no core_id or operands beyond defaults
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:34-38` (`TestAssembly.test_assemble_nop_halt`)

#### BA-005: Assembler Ignores Comments
- **Level:** VERIFIED
- **Given:** Text containing lines beginning with `#` and `//` interspersed with valid instructions
- **When:** `assemble()` is called
- **Then:** Only non-comment lines produce instructions (1 instruction from 3 lines of input)
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:40-43` (`TestAssembly.test_assemble_ignores_comments`)

#### BA-006: Assembler Handles Address Prefixes
- **Level:** VERIFIED
- **Given:** Text with address prefixes like `"0000: ACC ..."` and `"0001: HALT"`
- **When:** `assemble()` is called
- **Then:** Address prefixes (4-digit colon pattern) are stripped; instructions are correctly parsed
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:45-50` (`TestAssembly.test_assemble_with_address_prefix`)

#### BA-007: Disassemble-Assemble Round-Trip
- **Level:** VERIFIED
- **Given:** A manually constructed program `[ACC(3, (0,0,8)), FIRE(3, (64,)), LEAK(3, (240,)), HALT]`
- **When:** Program is disassembled to text, then reassembled
- **Then:** The reassembled program matches the original instruction-by-instruction: same length, same opcodes, same core_ids, same operands
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:52-65` (`TestAssembly.test_roundtrip_disassemble_assemble`)

#### BA-008: Invalid Instruction Raises ValueError
- **Level:** VERIFIED
- **Given:** Text `"BADOP core_0"` (unknown opcode)
- **When:** `assemble()` is called
- **Then:** Raises `ValueError` with message matching `"Cannot parse"`
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:67-69` (`TestAssembly.test_bad_instruction_raises`)

---

### Neuron Core State Management

#### BA-009: Neuron Core Initial State
- **Level:** VERIFIED
- **Given:** A freshly constructed `NeuronCore(core_id=0)`
- **When:** Initial state is inspected
- **Then:** `accumulator == 0`, `membrane_potential == 0`, `has_spiked is False`
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:75-79` (`TestNeuronCore.test_initial_state`)

#### BA-010: Neuron Core Reset
- **Level:** VERIFIED
- **Given:** A `NeuronCore` with modified state (`accumulator=100`, `membrane_potential=50`, `has_spiked=True`)
- **When:** `core.reset()` is called
- **Then:** All state returns to initial values: `accumulator == 0`, `membrane_potential == 0`, `has_spiked is False`
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:81-89` (`TestNeuronCore.test_reset`)

---

### SpikeCore CPU Simulator

#### BA-011: Program Loading
- **Level:** VERIFIED
- **Given:** A `SpikeCoreCPU(num_cores=4)` and a 2-instruction program `[ACC, HALT]`
- **When:** `cpu.load_program(prog)` is called
- **Then:** `len(cpu.program) == 2`
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:93-97` (`TestSpikeCoreCPU.test_load_program`)

#### BA-012: Weight Loading and Distribution Across Cores
- **Level:** VERIFIED
- **Given:** A weight matrix of shape `(2, 4)` with int8 dtype
- **When:** `cpu.load_weights(layer_id=0, weights_int8=w)` is called
- **Then:** Row 0 of the weight matrix is loaded into `cores[0].weights[:4]` and row 1 into `cores[1].weights[:4]`; each output neuron's weights go to a separate core
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:99-104` (`TestSpikeCoreCPU.test_load_weights`)

#### BA-013: ACC Instruction Computes Weighted Dot Product
- **Level:** VERIFIED
- **Given:** Core 0 weights set to `[2, 3, 1, -1]`, program is `[ACC core_0 bank_0 [0:4], HALT]`
- **When:** Input spikes `[1, 1, 1, 1]` are provided and `cpu.run(input_spikes, timesteps=1)` is called
- **Then:** `cores[0].accumulator == 5` (computed as `2+3+1-1 = 5`; dot product of weights and input)
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:106-124` (`TestSpikeCoreCPU.test_acc_instruction`)

#### BA-014: FIRE Emits Spike When Threshold Exceeded
- **Level:** VERIFIED
- **Given:** Core 0 weights `[50, 50]`, program `[ACC core_0 [0:2], FIRE core_0 threshold_64, HALT]`
- **When:** Input `[1, 1]` causes accumulation of 100, which exceeds threshold 64
- **Then:** Spike count for core 0 is 1; spike log contains exactly one entry `(timestep=0, core_id=0)`
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:126-143` (`TestSpikeCoreCPU.test_fire_with_spike`)

#### BA-015: FIRE Does NOT Emit Spike When Below Threshold
- **Level:** VERIFIED
- **Given:** Core 0 weights `[10, 10]`, program `[ACC core_0 [0:2], FIRE core_0 threshold_64, HALT]`
- **When:** Input `[1, 1]` causes accumulation of 20, which is below threshold 64
- **Then:** Spike count for core 0 is 0; spike log is empty
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:145-161` (`TestSpikeCoreCPU.test_fire_no_spike`)

#### BA-016: LEAK Decays Membrane Potential via Fixed-Point Multiply
- **Level:** VERIFIED
- **Given:** Core 0 `membrane_potential = 256`, LEAK instruction with `decay=128`
- **When:** `cpu._exec_leak(inst)` is called directly
- **Then:** `membrane_potential` becomes `128` (computed as `256 * 128 / 256 = 128`, using `>> 8` right-shift)
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:163-171` (`TestSpikeCoreCPU.test_leak_decays_membrane`)

#### BA-017: LEAK Works Within Full Program (ACC -> FIRE miss -> LEAK)
- **Level:** VERIFIED
- **Given:** Core 0 weights `[30, 30]`, program `[ACC core_0 [0:2], FIRE core_0 threshold_100, LEAK core_0 decay_128, HALT]`
- **When:** Input `[1, 1, 0, 0]` causes accumulation of 60 (below threshold 100), then LEAK applies decay
- **Then:** `membrane_potential == 30` (after FIRE miss, membrane absorbs 60; LEAK computes `60 * 128 / 256 = 30`)
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:173-191` (`TestSpikeCoreCPU.test_leak_in_program`)

#### BA-018: Two-Neuron Network Integration
- **Level:** VERIFIED
- **Given:** 2 neurons: core 0 with weights `[20, 20, 20]` (sum=60), core 1 with weights `[10, 10, 5]` (sum=25); both with FIRE threshold 30
- **When:** Input `[1, 1, 1]` is applied for 1 timestep
- **Then:** Core 0 fires (60 >= 30, spike count = 1); Core 1 does NOT fire (25 < 30, spike count = 0)
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:193-218` (`TestSpikeCoreCPU.test_two_neuron_network`)

#### BA-019: Output Activations Readout
- **Level:** VERIFIED
- **Given:** Core 0 weights `[30, 40]`, Core 1 weights `[10, 20]`, program runs ACC only (no FIRE) then HALT
- **When:** Input `[1, 1]`, then `cpu.get_output_activations([0, 1])` is called
- **Then:** Returns `[70, 30]` -- the raw accumulator values (30+40 and 10+20 respectively), allowing the caller to read pre-threshold activations as logits
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_simulator.py:220-237` (`TestSpikeCoreCPU.test_get_output_activations`)

---

### Weight Quantization

#### BA-020: Symmetric Quantization of Float32 Weights to Int8
- **Level:** VERIFIED
- **Given:** Float32 weight matrix `[[1.0, -0.5], [0.25, -1.0]]`
- **When:** `manual_quantize_weights(w)` is called
- **Then:** Output dtype is `int8`; `zero_point == 0` (symmetric); `scale ~= 1.0/127`; value `1.0` maps to `127` and value `-1.0` maps to `-127`
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_codegen.py:12-21` (`TestManualQuantization.test_symmetric_quantize`)

#### BA-021: Zero Weights Quantize to All Zeros
- **Level:** VERIFIED
- **Given:** All-zero weight matrix `np.zeros((3, 3))`
- **When:** `manual_quantize_weights(w)` is called
- **Then:** All quantized values are 0; `scale == 1.0` (degenerate case protection, as `abs_max < 1e-10` triggers the guard clause in `quantize.py:73-74`)
- **Edge Cases:** This IS the edge case -- the zero-weight boundary
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_codegen.py:23-27` (`TestManualQuantization.test_zero_weights`)

---

### BYOC Code Generation (Standalone Path)

#### BA-022: Single Layer with ReLU Activation Generates ACC+FIRE+LEAK per Neuron
- **Level:** VERIFIED
- **Given:** A single-layer config with `in_features=4`, `out_features=10`, `activation="relu"`
- **When:** `compile_from_torch(state_dict, layer_configs)` is called
- **Then:** Program ends with `HALT`; produces exactly 10 `ACC` instructions and 10 `FIRE` instructions (one per output neuron); each neuron gets ACC+FIRE+LEAK triplet
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_codegen.py:31-46` (`TestCompileFromTorch.test_single_layer_with_relu`)

#### BA-023: Output Layer with No Activation Generates ACC Only
- **Level:** VERIFIED
- **Given:** A single-layer config with `in_features=3`, `out_features=5`, `activation=None`
- **When:** `compile_from_torch(state_dict, layer_configs)` is called
- **Then:** Produces 0 `FIRE` instructions; produces exactly 5 `ACC` instructions (one per output neuron)
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_codegen.py:48-62` (`TestCompileFromTorch.test_output_layer_no_activation`)

#### BA-024: Two-Layer MLP Produces Sequential Core Assignments
- **Level:** VERIFIED
- **Given:** Two-layer MLP: layer 0 (4->8, relu), layer 1 (8->3, None)
- **When:** `compile_from_torch(state_dict, layer_configs)` is called
- **Then:** Program ends with `HALT`; 2 quantized weight matrices returned; core IDs assigned sequentially: layer 0 gets cores 0-7, layer 1 gets cores 8-10 (`acc_cores == [0,1,...,7,8,9,10]`)
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_codegen.py:64-83` (`TestCompileFromTorch.test_two_layer_mlp`)

#### BA-025: Disassemble Output Contains Readable Mnemonics
- **Level:** VERIFIED
- **Given:** A compiled program from an identity matrix (3x3) layer with relu
- **When:** `disassemble(program)` is called
- **Then:** Output text contains `"ACC"`, `"FIRE"`, and `"HALT"` substrings
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_codegen.py:85-97` (`TestCompileFromTorch.test_disassemble_output_readable`)

#### BA-026: MNIST-Sized MLP Compilation Produces Correct Shapes
- **Level:** VERIFIED
- **Given:** An MNIST-style MLP: weights `[64x784, 10x64]`, biases `[64, 10]`, activations `["relu", None]`
- **When:** `compile_nn_to_spikecore(weights, biases, activations)` is called
- **Then:** Program ends with `HALT`; 2 quantized weight sets returned; shapes preserved: `q_w[0] shape == (64, 784)`, `q_w[1] shape == (10, 64)`
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_codegen.py:101-119` (`TestCompileNNToSpikecore.test_mnist_mlp_shape`)

---

### Full Round-Trip Pipeline

#### BA-027: Numpy MLP Achieves >90% Training Accuracy
- **Level:** VERIFIED
- **Given:** Synthetic dataset with 300 samples, 16 features, 4 well-separated classes; MLP trained for 200 epochs with lr=0.01
- **When:** Forward pass predictions are compared against true labels
- **Then:** Accuracy exceeds 90% (assertion: `accuracy > 0.90`)
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_roundtrip.py:136-142` (`TestRoundTrip.test_pytorch_accuracy`)

#### BA-028: Quantized SpikeCore Predictions Match Float Predictions on >=70% of Samples
- **Level:** VERIFIED
- **Given:** A trained numpy MLP compiled to SpikeCore via `compile_nn_to_spikecore`; quantized forward pass simulated via `_spikecore_predict`
- **When:** 100 samples are classified by both the float model and the quantized SpikeCore model
- **Then:** Top-1 prediction agreement rate >= 70% (assertion: `match_rate >= 0.70`); acknowledges quantization error reduces accuracy
- **Edge Cases:** The `_spikecore_predict` helper handles the `x_abs_max < 1e-10` case by returning zeros (dead-neuron guard, line 108-109)
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_roundtrip.py:144-179` (`TestRoundTrip.test_spikecore_matches_pytorch`)

#### BA-029: Compiled Assembly Has Structurally Valid Program
- **Level:** VERIFIED
- **Given:** A trained 2-layer MLP (32 hidden, 4 output) compiled to SpikeCore
- **When:** Program structure is inspected
- **Then:** Program ends with `HALT`; number of ACC instructions equals `hidden_size + output_size` (32 + 4 = 36)
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_roundtrip.py:181-195` (`TestRoundTrip.test_compilation_produces_valid_assembly`)

#### BA-030: Simulator Produces Non-Empty Spike Activity
- **Level:** VERIFIED
- **Given:** A compiled program loaded into `SpikeCoreCPU(num_cores=128)` with quantized weights; input is a quantized sample from the training set
- **When:** `cpu.run(input_int8, timesteps=1)` is executed and `cpu.get_spike_log()` is read
- **Then:** Spike log is non-empty (`len(spike_log) > 0`), confirming the hidden layer with ReLU produces at least one spike from non-trivial input
- **Test Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_roundtrip.py:197-220` (`TestRoundTrip.test_spike_log_nonempty`)

---

## Error Contract

| Error Scenario | Expected Behavior | Test Evidence |
|---|---|---|
| Invalid/unknown instruction opcode in assembly text | `ValueError` raised with message matching `"Cannot parse"` | `test_simulator.py:67-69` |
| Core index exceeds `num_cores` during weight loading | `ValueError` raised with message citing layer ID and core count (in production code `hardware_model.py:65-67`, but NOT tested) | **UNTESTED** |
| All-zero weight matrix quantization | Returns all-zero int8 with `scale=1.0`, avoids division by zero | `test_codegen.py:23-27` |
| Near-zero activation input to quantized forward pass | Returns zero vector instead of NaN/inf | `test_roundtrip.py:108-109` (guard in `_spikecore_predict` helper) |
| TVM not installed for TVM-dependent functions | `RuntimeError("TVM is required...")` (in production code, but NOT tested) | **UNTESTED** |

---

## Coverage Gaps

### Untested Production Modules (Zero Test Coverage)

1. **`/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/relay_patterns.py`** -- The entire TVM Relay pattern matching module (`_make_dense_relu_pattern`, `_make_dense_bias_pattern`, `_make_qnn_dense_clip_pattern`, `spikecore_pattern_table`) has NO tests. This module defines the pattern table that maps TVM Relay subgraphs to SpikeCore primitives.

2. **`/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/visualize.py`** -- All four visualization functions (`plot_spike_raster`, `plot_compilation_graph`, `plot_weight_distribution`, `plot_comparison`) have NO tests. These include logic for handling empty spike logs, normalization of SpikeCore scores, and match/mismatch labeling.

### Untested Functions in Tested Modules

3. **`quantize_for_spikecore()`** (`quantize.py:22-53`) -- The TVM-based quantization path is untested (requires TVM).

4. **`manual_quantize_activations()`** (`quantize.py:81-104`) -- The activation quantization function is imported in `test_roundtrip.py:13` but never actually called in any test assertion. It uses asymmetric quantization (unsigned, qmax=255) which differs from the weight quantization logic.

5. **`register_spikecore_target()`** (`byoc_codegen.py:95-114`) -- TVM target registration is untested.

6. **`partition_for_spikecore()`** (`byoc_codegen.py:117-148`) -- TVM BYOC partitioning pipeline is untested.

7. **`_spikecore_codegen_callback()`** (`byoc_codegen.py:54-92`) -- TVM codegen callback is untested.

8. **`_compute_fire_shift()`** (`byoc_codegen.py:26-37`) -- The shift calculation (`ceil(log2(fan_in)) + 7`) is used in compilation but never directly tested in isolation. Edge case `fan_in <= 1` returns 7.

### Untested Behavioral Paths

9. **Multi-timestep execution** -- All tests use `timesteps=1`. The `run()` method's multi-timestep loop (`hardware_model.py:144-148`), including bus reset and input re-injection across timesteps, is never exercised.

10. **Activation bus overflow/clipping** -- The `FIRE` instruction clips values to `[-128, 127]` for the bus (`hardware_model.py:102`), but no test verifies this clipping boundary.

11. **FIRE shift operand** -- FIRE instructions can include a `shift` operand for right-shifting the accumulator output (`hardware_model.py:100`). The codegen produces these shifts (`byoc_codegen.py:205-207`), and the assembler regex recognizes `shift_N`, but no test verifies that a FIRE with shift produces correct rescaled output values.

12. **Layer-aware bus snapshotting** -- The simulator detects layer boundaries via ACC input range changes and refreshes the snapshot (`hardware_model.py:156-161`). This parallel-execution semantic is implicitly used in the round-trip test but never explicitly verified.

13. **Weight memory size limits** -- `WEIGHT_MEM_BYTES = 256` is the per-core limit (`hardware_model.py:17`). The `load_weights` method caps at `min(in_features, WEIGHT_MEM_BYTES)` (`hardware_model.py:68-69`), but no test verifies behavior when `in_features > 256`.

14. **Core overflow during weight loading** -- `load_weights` raises `ValueError` when `core_idx >= num_cores` (`hardware_model.py:64-67`), but this error path is never tested.

15. **`core_offset` parameter in `load_weights`** -- The optional `core_offset` parameter for explicit core placement (`hardware_model.py:51`) is never tested; all tests rely on the automatic `_next_core_offset` tracking.

16. **Skipped/commented tests** -- None found. All test functions are active.

---

## Mock Dependency Map

| Mocked Service | Expected Contract | Failure Modes Tested |
|---|---|---|
| **None** | This codebase uses NO mocks, stubs, or test doubles | N/A |

The test suite relies entirely on real object instances. External dependencies (TVM, PyTorch) are avoided in tests through the standalone compilation path and the pure-numpy MLP trainer. This is a deliberate design choice documented in `test_roundtrip.py:5-6`: "Tests the full pipeline without TVM by using the standalone compilation path. Trains a tiny MLP on synthetic data (to avoid MNIST download in CI)."

---

## Implicit Data Contracts (from Test Fixtures)

The following data shapes are verified through test assertions and fixture construction:

| Data Type | Shape / Dtype | Evidence |
|---|---|---|
| Input spikes/activations | `np.ndarray`, `dtype=int8` | All simulator tests; `test_roundtrip.py:213` |
| Weights (float) | `np.ndarray`, `dtype=float32`, shape `(out_features, in_features)` | `test_codegen.py:103-105`, `test_roundtrip.py:42-45` |
| Weights (quantized) | `np.ndarray`, `dtype=int8`, same shape as float | `test_codegen.py:15`, `test_codegen.py:118-119` |
| Quantization scale | `float` scalar | `test_codegen.py:18` |
| Quantization zero_point | `int`, always 0 for symmetric | `test_codegen.py:16` |
| Spike log entries | `tuple[int, int]` = `(timestep, core_id)` | `test_simulator.py:143` |
| Spike counts | `np.ndarray`, `dtype=int32`, shape `(num_cores,)` | `test_simulator.py:141,160` |
| Output activations | `np.ndarray`, `dtype=int32` | `test_simulator.py:236-237` |
| Layer configs for compile_from_torch | `dict` with keys: `name`, `in_features`, `out_features`, `activation` | `test_codegen.py:37-38` |
| State dict keys | Pattern: `"layers.{N}.weight"`, `"layers.{N}.bias"` | `test_codegen.py:32-35` |

---

## Summary Statistics

- **Total verified behaviors (BA-NNN):** 22 distinct behavioral assertions across 22 test functions
- **Test organization:** 3 files, 6 classes, 1 fixture
- **Modules with test coverage:** 3 of 6 (`assembly.py`, `hardware_model.py`, `byoc_codegen.py` standalone path, `quantize.py` partial)
- **Modules with zero coverage:** 2 of 6 (`relay_patterns.py`, `visualize.py`)
- **Functions partially covered:** `quantize.py` (2 of 3 functions tested)
- **Critical untested paths:** Multi-timestep simulation, FIRE shift rescaling, activation bus clipping, weight memory overflow, TVM integration (all 3 TVM-dependent modules)

## Infrastructure Analyst Report

# Infrastructure Analysis Report

## Configuration Overview

- **Config sources:** Dockerfile (build-time), docker-compose.yml (runtime), environment variables (3 in Dockerfile, 1 in docker-compose), hardcoded constants in Python modules
- **Feature flags:** 1 runtime feature flag (`HAS_TVM`) detected in 3 modules, controlling dual execution path selection
- **External dependencies:** 9 Python packages (pinned versions), 1 build dependency (Apache TVM from source), MNIST dataset (downloaded at runtime in notebook)
- **Infrastructure-as-code:** Dockerfile (multi-stage build), docker-compose.yml (single service)

---

## Non-Functional Requirements

### Security

#### IA-001: Jupyter Notebook Authentication Token
- **Requirement:** The Jupyter notebook server must require an authentication token to prevent unauthorized access to the interactive computing environment.
- **Implementation:** A static token `spikecore` is hardcoded in the Dockerfile CMD directive. Jupyter is launched with `--NotebookApp.token=spikecore`.
- **Config:** `NotebookApp.token=spikecore` (hardcoded in Dockerfile:63)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/Dockerfile`:61-63
```python
CMD ["jupyter", "notebook", "--ip=0.0.0.0", "--port=8888", \
     "--no-browser", "--allow-root", \
     "--NotebookApp.token=spikecore"]
```

#### IA-002: Container Runs as Root
- **Requirement:** The container process execution identity must be defined. Currently, the Jupyter server runs as root (`--allow-root`), with no non-root user created in the Dockerfile.
- **Implementation:** No `USER` directive in the Dockerfile; `--allow-root` is explicitly passed to Jupyter.
- **Config:** `--allow-root` flag (Dockerfile:62)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/Dockerfile`:61-63

#### IA-003: Network Binding on All Interfaces
- **Requirement:** The Jupyter notebook server binds to all network interfaces (`0.0.0.0`), making it accessible from outside the container.
- **Implementation:** `--ip=0.0.0.0` in the CMD directive. The docker-compose port mapping `8888:8888` exposes it to the host.
- **Config:** `--ip=0.0.0.0` (Dockerfile:61), `ports: "8888:8888"` (docker-compose.yml:5)
- **Evidence:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/Dockerfile`:61
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docker-compose.yml`:5

#### IA-004: No Secret Management Infrastructure
- **Requirement:** The system currently has no secrets requiring external management. The only credential-like value (Jupyter token) is hardcoded.
- **Implementation:** No `.env` files, no secret mounts, no environment-variable-based secrets in docker-compose.yml.
- **Config:** N/A
- **Evidence:** Absence of `.env` files (confirmed via glob search), no secret references in docker-compose.yml.

#### IA-005: Input Validation in Assembly Parser
- **Requirement:** The assembly parser must reject malformed instructions with descriptive error messages, preventing invalid programs from being loaded into the simulator.
- **Implementation:** Regex-based parsing with explicit `ValueError` on unrecognized instructions. Line number is included in error messages via exception chaining.
- **Config:** N/A
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/assembly.py`:84-128
```python
def _parse_line(line: str) -> Instruction | None:
    # ... regex matching ...
    raise ValueError(f"Cannot parse instruction: {line!r}")

def assemble(text: str) -> list[Instruction]:
    for lineno, line in enumerate(text.splitlines(), 1):
        try:
            inst = _parse_line(line)
        except ValueError as e:
            raise ValueError(f"Line {lineno}: {e}") from e
```

---

### Performance

#### IA-006: Hardware Architecture Capacity Constraints
- **Requirement:** The simulated neuromorphic chip has fixed capacity limits: 128 neuron cores, each with 256 bytes of local weight memory. Models must fit within these constraints.
- **Implementation:** `NUM_CORES = 128` and `WEIGHT_MEM_BYTES = 256` are module-level constants. The `SpikeCoreCPU` constructor accepts a configurable `num_cores` parameter (defaulting to 128). Weight loading validates against available cores and truncates weights exceeding memory.
- **Config:**
  - `NUM_CORES = 128` (hardware_model.py:16)
  - `WEIGHT_MEM_BYTES = 256` (hardware_model.py:17)
  - Constructor parameter `num_cores` defaults to `NUM_CORES`
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:16-17, 39, 64-70
```python
NUM_CORES = 128
WEIGHT_MEM_BYTES = 256  # per core

class SpikeCoreCPU:
    def __init__(self, num_cores: int = NUM_CORES):
        ...
    def load_weights(self, layer_id, weights_int8, core_offset=None):
        ...
        if core_idx >= self.num_cores:
            raise ValueError(
                f"Layer {layer_id}: need core {core_idx} but only {self.num_cores} available"
            )
        n = min(in_features, WEIGHT_MEM_BYTES)
```

#### IA-007: Integer-Only Arithmetic Datapath
- **Requirement:** The hardware simulator must operate with integer-only arithmetic: int8 weights, int16 activation bus, and int32 accumulator arithmetic. No floating-point operations are permitted on the simulated hardware path.
- **Implementation:** Weight arrays are `dtype=np.int8`. The activation bus is `dtype=np.int16`. Accumulation uses explicit `np.int32` casts. The FIRE instruction clamps output to `[-128, 127]` (int8 range).
- **Config:**
  - Weights: `np.int8` (hardware_model.py:27)
  - Bus: `np.int16` (hardware_model.py:141)
  - Accumulator: `np.int32` (hardware_model.py:81-83)
  - Output clamp: `np.clip(scaled, -128, 127)` (hardware_model.py:102)
- **Evidence:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:27, 81-83, 102, 141
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py`:43-47 (quantization config mirrors these constraints: `nbit_input=8, nbit_weight=8, nbit_activation=16`)

#### IA-008: Quantization Bit Width Constraints
- **Requirement:** Quantization must produce int8 weights and int8 activations to match the hardware's integer datapath. The quantization scheme supports configurable bit widths but defaults to 8-bit.
- **Implementation:** Symmetric quantization for weights (`scale = max(|w|) / 127`), asymmetric for activations (`scale = max(act) / 255`). Near-zero magnitude tensors (`abs_max < 1e-10`) are handled as a special case to avoid division by zero.
- **Config:**
  - `bits=8` default parameter (quantize.py:58, 84)
  - `qmax = 127` for weights (quantize.py:71)
  - `qmax = 255` for activations (quantize.py:96)
  - Zero-threshold: `1e-10` (quantize.py:73, 98)
  - TVM path: `global_scale=8.0` (quantize.py:49)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py`:56-104

#### IA-009: FIRE Instruction Shift Scaling
- **Requirement:** The FIRE instruction must rescale the wide int32 accumulator output back to int8 range for downstream layer consumption. The right-shift value is computed based on fan-in to prevent overflow.
- **Implementation:** `shift = ceil(log2(fan_in)) + 7`. For `fan_in <= 1`, shift defaults to 7. This ensures the output of `sum(int8 * int8)` over `fan_in` inputs is scaled back to `[-128, 127]`.
- **Config:**
  - Base shift: `7` for scaling `127*127 -> 127` (byoc_codegen.py:36)
  - Formula: `ceil(log2(fan_in)) + 7` (byoc_codegen.py:37)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py`:26-37
```python
def _compute_fire_shift(fan_in: int) -> int:
    if fan_in <= 1:
        return 7
    return math.ceil(math.log2(fan_in)) + 7
```

#### IA-010: LEAK Decay Fixed-Point Arithmetic
- **Requirement:** Membrane potential decay must use fixed-point multiplication: `leaked = (membrane_potential * decay) >> 8`, where `decay` is an 8-bit value representing the fraction `decay/256`.
- **Implementation:** Right-shift by 8 bits implements division by 256. A decay of 240 yields ~93.75% retention; a decay of 128 yields 50% retention.
- **Config:** Default decay value in BYOC codegen: `240` (byoc_codegen.py:84, 209)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:110-115
```python
def _exec_leak(self, inst: Instruction) -> None:
    core = self.cores[inst.core_id]
    (decay,) = inst.operands
    leaked = (core.membrane_potential * decay) >> 8
    core.membrane_potential = leaked
```

#### IA-011: TVM Compilation Optimization Level
- **Requirement:** TVM compilation passes must execute at optimization level 3 (`opt_level=3`), the highest level, to ensure maximum graph optimization including operator fusion.
- **Implementation:** `tvm.transform.PassContext(opt_level=3)` wraps both quantization and partitioning passes.
- **Config:** `opt_level=3` (quantize.py:40, byoc_codegen.py:145)
- **Evidence:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py`:40
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py`:145

#### IA-012: PyTorch CPU-Only Execution
- **Requirement:** The system must operate without GPU hardware. PyTorch is pinned to CPU-only builds to reduce image size and eliminate CUDA dependency.
- **Implementation:** `torch==2.2.2+cpu` and `torchvision==0.17.2+cpu` in requirements.txt. The pip install uses `--extra-index-url https://download.pytorch.org/whl/cpu`.
- **Config:** requirements.txt lines 1-2, Dockerfile:54
- **Evidence:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/requirements.txt`:1-2
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/Dockerfile`:53-54

---

### Reliability

#### IA-013: Dual Execution Path (TVM / Standalone)
- **Requirement:** The system must provide a functional compilation pipeline both with and without TVM installed. The TVM dependency is optional; all core functionality (quantization, code generation, simulation) must work via a standalone path.
- **Implementation:** Each TVM-dependent module wraps the TVM import in a `try/except ImportError` block and sets a module-level `HAS_TVM` boolean. Functions that require TVM raise `RuntimeError` with a descriptive message. The standalone path (`compile_from_torch`, `compile_nn_to_spikecore`, `manual_quantize_weights`) provides equivalent functionality using only numpy.
- **Config:** `HAS_TVM` boolean flag in `quantize.py`:19, `relay_patterns.py`:26, `byoc_codegen.py`:47
- **Evidence:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py`:12-19 (import guard)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/relay_patterns.py`:14-26 (import guard)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py`:39-47 (import guard)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py`:155-215 (standalone compile_from_torch)

```python
try:
    import tvm
    from tvm import relay
    HAS_TVM = True
except ImportError:
    HAS_TVM = False
```

#### IA-014: Weight Loading Boundary Validation
- **Requirement:** Weight loading must fail explicitly when the model exceeds hardware capacity, rather than silently truncating or corrupting data.
- **Implementation:** `load_weights` raises `ValueError` when the required core index exceeds `self.num_cores`. Weight columns exceeding `WEIGHT_MEM_BYTES` are silently truncated via `min(in_features, WEIGHT_MEM_BYTES)`.
- **Config:** N/A (derived from IA-006 capacity constants)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:50-70
```python
if core_idx >= self.num_cores:
    raise ValueError(
        f"Layer {layer_id}: need core {core_idx} but only {self.num_cores} available"
    )
n = min(in_features, WEIGHT_MEM_BYTES)
self.cores[core_idx].weights[:n] = weights_int8[i, :n]
```

#### IA-015: ACC Instruction Input Range Clamping
- **Requirement:** The ACC instruction must handle input ranges that exceed the actual bus length gracefully, without array index errors.
- **Implementation:** `actual_end = min(end, len(bus))` clamps the read range. If `actual_end <= start`, the instruction is a no-op.
- **Config:** N/A
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:72-84
```python
def _exec_acc(self, inst: Instruction, bus: np.ndarray) -> None:
    bank, start, end = inst.operands
    actual_end = min(end, len(bus))
    if actual_end <= start:
        return
```

#### IA-016: Layer-Aware Parallel Execution Semantics
- **Requirement:** Within a single layer, all ACC instructions must read from a consistent snapshot of the activation bus, simulating parallel execution across neuron cores. When the layer boundary changes (detected by a change in ACC input range), the snapshot refreshes.
- **Implementation:** The `run()` method maintains a `snapshot` copy of the bus. It detects layer boundaries by tracking `last_acc_range`. When the ACC input range tuple changes, a new snapshot is taken from the live bus.
- **Config:** N/A
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:150-162
```python
last_acc_range = None
snapshot = bus.copy()

for inst in self.program:
    if inst.opcode == Opcode.ACC:
        acc_range = (inst.operands[1], inst.operands[2])
        if acc_range != last_acc_range:
            snapshot = bus.copy()
            last_acc_range = acc_range
        self._exec_acc(inst, snapshot)
```

#### IA-017: Quantization Zero-Division Protection
- **Requirement:** Quantization functions must handle tensors with all-zero or near-zero values without producing NaN or infinity.
- **Implementation:** Both `manual_quantize_weights` and `manual_quantize_activations` check `abs_max < 1e-10` and return zero arrays with `scale=1.0` as early return.
- **Config:** Threshold: `1e-10` (quantize.py:73, 98)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py`:72-74, 97-99
```python
if abs_max < 1e-10:
    return np.zeros_like(weights_fp32, dtype=np.int8), 1.0, 0
```

#### IA-018: Assembly Parse Error Enrichment
- **Requirement:** Assembly parsing errors must include the line number of the failing instruction to aid debugging.
- **Implementation:** The `assemble()` function wraps `_parse_line()` calls in try/except and re-raises with the line number prepended, using exception chaining (`from e`).
- **Config:** N/A
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/assembly.py`:118-128

---

### Observability

#### IA-019: Spike Activity Logging
- **Requirement:** The simulator must record a complete log of all spike events (timestep, core_id) for post-simulation analysis and visualization.
- **Implementation:** `SpikeCoreCPU.spike_log` is a list of `(timestep, core_id)` tuples. After each timestep, cores that have spiked are appended. The log is cleared at the start of each `run()` call. Accessed via `get_spike_log()`.
- **Config:** N/A
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:43, 132, 170-175, 179-181
```python
self.spike_log: list[tuple[int, int]] = []  # (timestep, core_id)
...
self.spike_log.clear()
...
if core.has_spiked:
    self.spike_log.append((t, core.core_id))
```

#### IA-020: Spike Count Accumulation
- **Requirement:** The simulator must return per-core spike counts over the full simulation as a summary metric.
- **Implementation:** `run()` returns `np.zeros(self.num_cores, dtype=np.int32)` array, incrementing `spike_counts[core.core_id]` on each spike event.
- **Config:** N/A
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:133, 174

#### IA-021: Output Activation Readout
- **Requirement:** The simulator must support reading final accumulator + membrane potential values from designated output cores, enabling classification comparison.
- **Implementation:** `get_output_activations(output_core_ids)` returns `accumulator + membrane_potential` for specified cores as an int32 numpy array.
- **Config:** N/A
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:183-193

#### IA-022: Visualization Suite
- **Requirement:** The system must provide publication-quality visualizations of: spike raster plots, compilation graph partitioning, weight distribution histograms, and PyTorch vs. SpikeCore output comparison.
- **Implementation:** Four visualization functions in `visualize.py`, all accepting optional matplotlib `Axes` for composability. Default figure sizes are hardcoded.
- **Config:**
  - Spike raster figsize: `(12, 6)` (visualize.py:23)
  - Compilation graph figsize: `(14, 5)` (visualize.py:76)
  - Weight histogram figsize: `(8, 4)` (visualize.py:140)
  - Comparison figsize: `(10, 5)` (visualize.py:182)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/visualize.py`:17-228

#### IA-023: No Structured Logging or Log Levels
- **Requirement (Implicit):** The library modules contain no logging infrastructure. There are no `import logging` statements, no logger instances, and no log-level-based output anywhere in the `spikecore` package. All diagnostic output is deferred to the notebook's `print()` statements.
- **Implementation:** N/A (absent)
- **Config:** N/A
- **Evidence:** Confirmed via grep: no `logging`, `logger`, `log.info`, `log.debug`, `log.warning`, or `log.error` patterns found in any `.py` file under `spikecore/`.

---

### Deployment

#### IA-024: Multi-Stage Docker Build
- **Requirement:** The Docker image must include TVM compiled from source alongside the Python runtime, using a multi-stage build to manage the complex build toolchain.
- **Implementation:** Two-stage build: `tvm-builder` stage (based on `python:3.11-slim`) installs build tools, clones TVM from `main` branch, and compiles with Ninja. Runtime stage copies only the built artifacts. Build parallelism uses `$(nproc)`.
- **Config:**
  - Base image: `python:3.11-slim` (Dockerfile:4, 34)
  - TVM source: `https://github.com/apache/tvm`, branch `main`, `--depth 1` (Dockerfile:23-24)
  - LLVM version: 15 (Dockerfile:11-14, 28)
  - TVM options: `USE_LLVM ON`, `USE_RELAY_DEBUG ON` (Dockerfile:28-29)
  - Build generator: Ninja (Dockerfile:31)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/Dockerfile`:1-63

#### IA-025: TVM Environment Variables
- **Requirement:** Three environment variables must be set for TVM to function within the container: the TVM home directory, the Python path (including TVM Python bindings and the lab directory), and the TVM library path.
- **Implementation:** Set via `ENV` directives in the Dockerfile.
- **Config:**
  - `TVM_HOME=/opt/tvm` (Dockerfile:47)
  - `PYTHONPATH=/opt/tvm/python:/lab:${PYTHONPATH}` (Dockerfile:48)
  - `TVM_LIBRARY_PATH=/opt/tvm/build` (Dockerfile:49)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/Dockerfile`:47-49

#### IA-026: Bytecode Write Suppression
- **Requirement:** Python bytecode file generation (`.pyc`) must be suppressed in the development container to prevent stale cache artifacts when source files are changed via volume mounts.
- **Implementation:** `PYTHONDONTWRITEBYTECODE=1` environment variable set in docker-compose.yml.
- **Config:** `PYTHONDONTWRITEBYTECODE=1` (docker-compose.yml:11)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docker-compose.yml`:11

#### IA-027: Volume Mount Strategy for Development
- **Requirement:** Source code, notebooks, and tests must be mounted into the container as volumes so that changes on the host are immediately reflected without rebuilding the image.
- **Implementation:** Three bind mounts map host directories into `/lab/` inside the container.
- **Config:**
  - `./notebooks:/lab/notebooks`
  - `./spikecore:/lab/spikecore`
  - `./tests:/lab/tests`
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docker-compose.yml`:7-9

#### IA-028: Exposed Port Configuration
- **Requirement:** The Jupyter notebook server must be accessible from the host on port 8888.
- **Implementation:** `EXPOSE 8888` in Dockerfile and `ports: "8888:8888"` in docker-compose.yml.
- **Config:** Port `8888` (Dockerfile:59, docker-compose.yml:5)
- **Evidence:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/Dockerfile`:59
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docker-compose.yml`:5

#### IA-029: Pinned Dependency Versions
- **Requirement:** All Python dependencies must be pinned to exact versions to ensure reproducible builds.
- **Implementation:** `requirements.txt` specifies exact versions with `==` for all 9 packages. TVM is built from `main` branch (not pinned to a tag/commit).
- **Config:**
  - `torch==2.2.2+cpu`
  - `torchvision==0.17.2+cpu`
  - `numpy==1.26.4`
  - `matplotlib==3.9.2`
  - `jupyter==1.0.0`
  - `notebook==7.2.2`
  - `onnx==1.16.2`
  - `pytest==8.3.3`
  - `scipy==1.14.1`
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/requirements.txt`:1-9

#### IA-030: TVM Debug Mode Enabled
- **Requirement:** The TVM build has Relay debug mode enabled (`USE_RELAY_DEBUG ON`), which provides additional IR validation and debug output during compilation.
- **Implementation:** `echo "set(USE_RELAY_DEBUG ON)" >> config.cmake` in the Dockerfile build stage.
- **Config:** `USE_RELAY_DEBUG=ON` (Dockerfile:29)
- **Evidence:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/Dockerfile`:29

#### IA-031: Test Runner Configuration
- **Requirement:** The project uses pytest as its test runner. Tests are organized in a `tests/` directory with an `__init__.py` module marker.
- **Implementation:** `pytest==8.3.3` in requirements.txt. Three test modules: `test_simulator.py`, `test_codegen.py`, `test_roundtrip.py`. No `pytest.ini`, `pyproject.toml`, or `setup.cfg` configuration files exist. The design document specifies `pytest tests/ -v` as the verification command.
- **Config:** pytest version `8.3.3`, no custom pytest configuration
- **Evidence:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/requirements.txt`:8
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md`:66

#### IA-032: No CI/CD Pipeline
- **Requirement (Implicit):** There is no continuous integration or continuous deployment configuration. No GitHub Actions, GitLab CI, Jenkins, or other CI/CD files are present. The project is not a git repository.
- **Implementation:** N/A (absent)
- **Config:** N/A
- **Evidence:** No `.github/`, `.gitlab-ci.yml`, `Jenkinsfile`, or similar files found. The working directory is confirmed not to be a git repository.

---

## External Dependency Map

| Dependency | Type | Purpose | Config | Failure Mode |
|-----------|------|---------|--------|-------------|
| Apache TVM (main branch) | Build dependency | Compiler framework for Relay IR, quantization, BYOC | Cloned from GitHub at build time, `--depth 1` | Graceful degradation: standalone path via `HAS_TVM=False` |
| PyTorch 2.2.2+cpu | Python package | Model definition, training, inference reference | `requirements.txt:1`, CPU-only index | Required for notebook training; not required for spikecore package |
| torchvision 0.17.2+cpu | Python package | MNIST dataset download and transforms | `requirements.txt:2` | Required only for notebook MNIST workflow |
| numpy 1.26.4 | Python package | Core numerical computation, array operations | `requirements.txt:3` | Hard dependency for all spikecore modules |
| matplotlib 3.9.2 | Python package | Visualization (spike rasters, weight histograms) | `requirements.txt:4` | Required only for `visualize.py` |
| scipy 1.14.1 | Python package | Scientific computing utilities | `requirements.txt:9` | Not directly imported in spikecore; potentially for notebook use |
| jupyter 1.0.0 + notebook 7.2.2 | Python package | Interactive notebook environment | `requirements.txt:5-6` | Required for notebook-based workflow; not for library use |
| onnx 1.16.2 | Python package | ONNX model interchange format | `requirements.txt:7` | Not directly imported in spikecore; potentially for future use |
| pytest 8.3.3 | Python package | Test runner | `requirements.txt:8` | Required only for test execution |
| MNIST dataset | External data | Training/test data for notebook demo | Downloaded via torchvision at runtime to `./data` | Only needed for notebook demo; tests use synthetic data |
| LLVM 15 | System library | Backend for TVM compilation | `Dockerfile:11-14` | Required for TVM build; not for standalone path |

---

## Configuration Reference

| Config Key | Default | Purpose | Category |
|-----------|---------|---------|----------|
| `NUM_CORES` | `128` | Number of neuron cores in hardware model | Performance |
| `WEIGHT_MEM_BYTES` | `256` | Per-core weight memory in bytes | Performance |
| `num_cores` (constructor param) | `128` | Configurable core count for SpikeCoreCPU | Performance |
| `bits` (quantize param) | `8` | Quantization bit width for weights/activations | Performance |
| `global_scale` (TVM qconfig) | `8.0` | Global quantization scale for TVM path | Performance |
| `nbit_input` | `8` | TVM quantization input bit width | Performance |
| `nbit_weight` | `8` | TVM quantization weight bit width | Performance |
| `nbit_activation` | `16` | TVM quantization accumulator bit width (int16) | Performance |
| `opt_level` | `3` | TVM pass optimization level | Performance |
| `decay` (LEAK default) | `240` | Membrane potential decay factor (240/256 ~ 93.75%) | Performance |
| `threshold` (FIRE default in BYOC) | `64` | Default firing threshold in BYOC codegen | Performance |
| Zero-division threshold | `1e-10` | Minimum abs_max before treating as zero | Reliability |
| `TVM_HOME` | `/opt/tvm` | TVM installation directory | Deployment |
| `PYTHONPATH` | `/opt/tvm/python:/lab` | Python module search path | Deployment |
| `TVM_LIBRARY_PATH` | `/opt/tvm/build` | TVM shared library path | Deployment |
| `PYTHONDONTWRITEBYTECODE` | `1` | Suppress .pyc file generation | Deployment |
| `NotebookApp.token` | `spikecore` | Jupyter authentication token | Security |
| `--ip` (Jupyter) | `0.0.0.0` | Network binding interface | Security |
| Port | `8888` | Jupyter server port | Deployment |
| `USE_RELAY_DEBUG` | `ON` | TVM Relay IR debug mode | Deployment |
| `timesteps` (run param) | `1` | Default simulation timesteps | Performance |
| Spike raster figsize | `(12, 6)` | Default figure size for raster plots | Observability |
| Compilation graph figsize | `(14, 5)` | Default figure size for graph plots | Observability |
| Weight histogram figsize | `(8, 4)` | Default figure size for weight plots | Observability |
| Comparison figsize | `(10, 5)` | Default figure size for comparison plots | Observability |
| Round-trip match threshold | `70%` | Minimum SpikeCore/PyTorch prediction agreement | Reliability |
| Float model accuracy threshold | `90%` | Minimum training accuracy for sanity check | Reliability |

---

## Summary of Key Findings

This codebase is a self-contained neuromorphic computing lab with 32 distinct non-functional requirements identified. The most architecturally significant findings are:

1. **Dual execution path** (IA-013) is the primary reliability pattern -- the `HAS_TVM` feature flag in three modules allows the entire compilation and simulation pipeline to function without TVM, which is only available inside the Docker container.

2. **Hardware capacity constraints** (IA-006, IA-007, IA-008, IA-009, IA-010) encode a detailed model of a fictional neuromorphic chip. These are not arbitrary limits but a coherent hardware specification: 128 cores, 256 bytes/core, int8/int16/int32 datapath, threshold-based firing, and fixed-point decay.

3. **Security posture is minimal** (IA-001 through IA-004). The system uses a hardcoded Jupyter token, runs as root, and binds to all interfaces. This is appropriate for a local development lab but would require hardening for any shared or production deployment.

4. **Observability is domain-specific** (IA-019 through IA-023). Rather than traditional application logging, the system provides neuromorphic-specific observability: spike event logs, per-core spike counts, and output activation readout. There is no structured logging framework in the library code.

5. **Deployment is fully containerized** (IA-024 through IA-032) with a multi-stage Docker build. All Python dependencies are pinned. However, TVM is built from the `main` branch without a pinned commit hash, introducing potential reproducibility risk. There is no CI/CD pipeline.

## Documentation Miner Report

# Documentation Mining Report

## Documentation Landscape

- **README files:** 2 relevant (root `README.md`, `docs/plans/2026-02-17-spikecore-lab-design.md`; pytest cache README excluded)
- **Inline comments:** Moderate density. Most comments are algorithmic explanations and domain mapping notes. Comments are present in all `.py` files, with the richest density in `hardware_model.py`, `byoc_codegen.py`, and test files.
- **API docs (docstrings):** Excellent coverage. Every public class, method, and function has a docstring with Args/Returns sections. Private methods also have one-line docstrings.
- **Changelogs:** None present. No CHANGELOG.md, HISTORY.md, or release notes.
- **TODO/FIXME count:** 0 explicit TODO/FIXME/HACK/XXX markers in the codebase.
- **Architecture docs:** 1 design document (`docs/plans/2026-02-17-spikecore-lab-design.md`) with full ADR-style key decisions section.
- **Contributing guides:** None present.
- **Jupyter notebook:** 1 notebook (`01_spikecore_tvm.ipynb`) with 11 markdown cells and 10 code cells serving as a walkthrough/demo.

---

## Design Rationale

### DM-001: TVM BYOC Over Custom LLVM Backend
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md`:53
- **Statement:** "TVM BYOC over custom LLVM backend -- BYOC is the actual mechanism Intel would use; avoids LLVM rabbit hole"
- **Implied Requirement:** The compilation pipeline must use TVM's BYOC framework as the integration path, matching the approach Intel would use for real Loihi hardware. The system shall not implement a custom LLVM backend.
- **Confidence:** High -- explicit rationale with both positive ("actual mechanism Intel would use") and negative ("avoids LLVM rabbit hole") justification.

### DM-002: Docker Over Conda/Venv for Reproducibility
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md`:54
- **Statement:** "Docker over conda/venv -- TVM source build has many system deps; container makes it reproducible"
- **Implied Requirement:** The system must provide a Docker-based reproducible build environment because TVM's source build involves many system-level dependencies that are difficult to manage with Python-only tooling.
- **Confidence:** High -- explicit.

### DM-003: PyTorch CPU-Only for Simplicity
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md`:55
- **Statement:** "PyTorch CPU-only -- no GPU needed, simpler Docker build, focuses on the compilation pipeline"
- **Implied Requirement:** The system shall not require GPU hardware. All operations are CPU-only. The compilation pipeline, not training performance, is the primary concern.
- **Confidence:** High -- explicit.

### DM-004: MNIST MLP as Minimal Sufficient Model
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md`:56
- **Statement:** "MNIST MLP over anything fancier -- just enough to have real weights and meaningful classification"
- **Implied Requirement:** The demonstration model (784->64->10 MLP) must be the simplest possible network that still produces meaningful classification results. The model serves the pipeline demonstration, not state-of-the-art accuracy.
- **Confidence:** High -- explicit.

### DM-005: MLIR Explicitly Deferred to Phase 2
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md`:58
- **Statement:** "MLIR deferred to Phase 2 -- adding torch-mlir doubles build complexity; TVM BYOC already demonstrates the full pipeline"
- **Implied Requirement:** The Phase 1 system explicitly does NOT include MLIR integration. This was a conscious scoping decision, not an oversight. The BYOC path is deemed sufficient to demonstrate the full pipeline.
- **Confidence:** High -- explicit deferral with complexity justification.

### DM-006: Mandatory int8 Quantization Bridge
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md`:59
- **Statement:** "int8 quantization -- mandatory bridge between float PyTorch world and integer-only SpikeCore"
- **Implied Requirement:** The system must include a quantization step converting float32 to int8. This is not optional -- it is a "mandatory bridge" because the hardware target only operates on integers.
- **Confidence:** High -- explicitly called "mandatory."

### DM-007: Standalone Compilation Path for TVM-Free Environments
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md`:60
- **Statement:** "Standalone compilation path -- allows testing and demonstration without TVM build"
- **Implied Requirement:** The system must support a non-TVM compilation path that produces identical SpikeCore assembly output. This enables testing in CI environments and local development without the heavyweight TVM build.
- **Confidence:** High -- explicit.

### DM-008: Dual Path Equivalence Guarantee
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md`:49-50
- **Statement:** "Both paths produce the same SpikeCore assembly and use the same simulator."
- **Implied Requirement:** The TVM BYOC path and the standalone path are functionally equivalent. They must produce the same assembly and share the same simulator backend.
- **Confidence:** High -- explicit equivalence claim.

### DM-009: Return Assembly as Text (Not Binary)
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py`:108-109
- **Statement:** "Return assembly as a runtime module (string representation) / In a real target, this would emit binary; here we return text"
- **Implied Requirement:** The codegen produces human-readable text assembly rather than binary code. This is a deliberate simplification for inspectability. A production system would emit binary.
- **Confidence:** High -- explicit "in a real target" qualifier.

### DM-010: Always Prefer SpikeCore Offloading
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py`:114
- **Statement:** "return 1  # Always prefer offloading to SpikeCore"
- **Implied Requirement:** The BYOC cost estimator always prefers offloading to SpikeCore over host execution. There is no cost-based decision logic -- this is a simplification where every eligible subgraph is offloaded.
- **Confidence:** High -- explicit inline comment.

### DM-011: Layer-Aware Bus Snapshot for Parallel Semantics
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:150-151
- **Statement:** "Layer-aware execution: snapshot bus at layer boundaries / so same-layer cores read consistent input (parallel semantics)"
- **Implied Requirement:** The simulator must emulate parallel execution within a layer by snapshotting the activation bus at layer boundaries. Cores in the same layer must read the same input state, even though the simulator executes them sequentially. This preserves the semantics of real parallel hardware.
- **Confidence:** High -- explicit comment with rationale ("parallel semantics").

### DM-012: FIRE Right-Shift for Inter-Layer Rescaling
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:89-91
- **Statement:** "Operands: (threshold, shift) where shift is right-shift bits applied to the activation before writing to the bus. This rescales the wide accumulator output to int8 range for the next layer."
- **Implied Requirement:** The FIRE instruction includes a right-shift operand to rescale the int32 accumulator result back into int8 range for the downstream activation bus. This is the mechanism for maintaining numerical precision across layers in an integer-only pipeline.
- **Confidence:** High -- detailed docstring.

### DM-013: FIRE Shift Calculation Formula
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py`:28-33
- **Statement:** "The ACC accumulator holds sum(int8 * int8) over fan_in inputs. Max value ~ fan_in * 127 * 127. We need to shift right so the output fits in [-128, 127] for the downstream bus. shift = ceil(log2(fan_in)) + 7"
- **Implied Requirement:** The shift parameter in FIRE instructions is computed as `ceil(log2(fan_in)) + 7`. This formula derives from the worst-case accumulator magnitude analysis. The "+7" accounts for the int8 * int8 product range.
- **Confidence:** High -- mathematical derivation documented.

### DM-014: Fixed-Point Leak Decay
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:111
- **Statement:** "LEAK: decay membrane potential (fixed-point multiply by decay/256)."
- **Implied Requirement:** The LEAK instruction uses fixed-point arithmetic where the decay factor is a fraction with denominator 256 (i.e., 8-bit fractional representation). A decay value of 240 means a 240/256 = 93.75% retention.
- **Confidence:** High -- explicit formula in docstring.

### DM-015: Unsigned int8 Wrapping for Activations
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py`:103
- **Statement:** "Store as int8 (values 0-127 fit; 128-255 wraps but SpikeCore handles unsigned)"
- **Implied Requirement:** The activation quantization stores values as int8, even though post-ReLU activations are unsigned. Values in the 128-255 range will wrap to negative int8 values, but the SpikeCore hardware is documented as handling this correctly.
- **Confidence:** Medium -- the comment asserts SpikeCore "handles unsigned" but the mechanism is not further documented, creating a potential specification gap.

---

## Stated Purpose

### DM-016: Project Purpose -- Compilation Pipeline Demo
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/README.md`:3
- **Statement:** "PyTorch -> TVM BYOC -> Neuromorphic Target -- A complete compilation pipeline demo."
- **Implied Requirement:** The system is a self-contained demonstration of the complete compilation pipeline from ML framework to neuromorphic hardware, not a production compiler.

### DM-017: Every Stage Must Be Visible and Inspectable
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/README.md`:7
- **Statement:** "Every compilation stage -- from floating-point model to integer-only neuromorphic assembly -- is visible and inspectable in a Jupyter notebook."
- **Implied Requirement:** Inspectability is a first-class requirement. Each pipeline stage must produce observable, human-readable intermediate output in the notebook. The notebook is not just a runner but an inspection tool.

### DM-018: Bridging ML and Hardware Compilation
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/README.md`:9
- **Statement:** "This project bridges the gap between ML framework development and hardware-targeted compilation, demonstrating the exact workflow used to bring new accelerators (like Intel's Loihi) into a compiler ecosystem."
- **Implied Requirement:** The pipeline must reflect the actual workflow for integrating new hardware accelerators into compiler ecosystems. It is not an abstract educational tool but a demonstration of a production-grade workflow pattern.

### DM-019: SpikeCore -- Simple Yet Realistic
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/README.md`:13
- **Statement:** "SpikeCore is a fictional neuromorphic chip designed to be simple enough to understand completely, yet realistic enough to demonstrate real compilation challenges"
- **Implied Requirement:** The SpikeCore hardware model must balance simplicity (fully understandable) with realism (encountering genuine compilation challenges like quantization, partitioning, resource constraints). It is not a toy -- it must produce real compilation challenges.

### DM-020: Onboarding Preparation for Intel Role
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md`:8-10
- **Statement:** "This project bridges the gap between Daniel's SoC/embedded experience and AI/LLM work -- specifically model optimization, graph compilation, and hardware-targeted code generation. [...] This serves as onboarding preparation for the Intel AI Software Architect -- Neuromorphic Computing role."
- **Implied Requirement:** The system must demonstrate competence in three specific domains: (1) model optimization, (2) graph compilation, and (3) hardware-targeted code generation. These are the three capabilities relevant to the target Intel role.

### DM-021: SpikeCore Hardware Specification
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/README.md`:15-20
- **Statement:** "128 Neuron cores | 256 bytes per core (int8) weight memory | int32 (32-bit signed) accumulator | Event-driven (spike-based) execution model"
- **Implied Requirement:** The hardware model must implement exactly these constraints: 128 cores, 256 bytes weight memory per core, int32 accumulator, event-driven execution. These are hard specifications.

### DM-022: SpikeCore ISA Specification
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/README.md`:22-31
- **Statement:** "5 opcodes: ACC (Weighted accumulate), FIRE (Threshold + emit spike), LEAK (Membrane decay), NOP (Pipeline bubble), HALT (Stop execution)"
- **Implied Requirement:** The ISA is fixed at exactly 5 instructions with these specific semantics. This is the complete instruction set.

### DM-023: Module Docstring Purpose -- SpikeCore Package
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/__init__.py`:1
- **Statement:** "SpikeCore -- A fictional neuromorphic hardware target for TVM BYOC demonstration."
- **Implied Requirement:** The package's stated identity is as a TVM BYOC demonstration target. Its "fictional" nature is declared at the package level.

### DM-024: Notebook Purpose -- 10-Stage Walkthrough
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/notebooks/01_spikecore_tvm.ipynb` cell-0
- **Statement:** "This notebook demonstrates the full compilation pipeline from a trained PyTorch model to a fictional neuromorphic hardware target ('SpikeCore') using TVM's BYOC framework."
- **Implied Requirement:** The notebook must cover all 8 listed pipeline stages in sequence, with each stage producing visible output.

---

## Domain Vocabulary

| Term | Source | Meaning | Used Consistently? |
|------|--------|---------|-------------------|
| SpikeCore | README.md, all modules | Fictional neuromorphic chip/target | Yes |
| ACC | assembly.py:24, README.md:26 | Weighted accumulate instruction (dot product of inputs x weights) | Yes |
| FIRE | assembly.py:25, README.md:27 | Threshold + emit spike instruction | Yes |
| LEAK | assembly.py:26, README.md:28 | Membrane decay instruction (fixed-point) | Yes |
| NOP | assembly.py:27, README.md:29 | No operation / pipeline bubble | Yes |
| HALT | assembly.py:28, README.md:30 | Stop execution instruction | Yes |
| Neuron Core | hardware_model.py:21, README.md:17 | A single processing unit with local weights/accumulator/membrane | Yes |
| Membrane Potential | hardware_model.py:26 | Accumulated sub-threshold state that persists across timesteps | Yes |
| Spike / has_spiked | hardware_model.py:28 | Boolean event emitted when accumulator exceeds threshold | Yes |
| Activation Bus | hardware_model.py:139-141 | Shared int16 communication channel between layers | Yes |
| Spike Log | hardware_model.py:43 | Record of (timestep, core_id) events | Yes |
| Weight Bank | assembly.py:11 | Local weight memory partition index within a core | Yes |
| BYOC | byoc_codegen.py:1, README.md | TVM's Bring Your Own Codegen framework | Yes |
| Relay IR | byoc_codegen.py:4, README.md:93 | TVM's high-level graph intermediate representation | Yes |
| Composite Pattern | relay_patterns.py:1-9 | Fused Relay subgraph mapped to SpikeCore primitives | Yes |
| Partition / Partitioned Graph | byoc_codegen.py:8-9 | Split of Relay graph into host vs. SpikeCore subgraphs | Yes |
| Standalone Path | byoc_codegen.py:152 | Non-TVM compilation path with manual quantization | Yes |
| Spike Raster | visualize.py:2-3 | Visualization: neuron cores on y-axis, timesteps on x-axis | Yes |
| Rate-coded Inference | hardware_model.py:187 | Single-timestep inference where accumulator values = logits | Yes |
| Accumulator | hardware_model.py:5, README.md:19 | int32 register holding weighted sum within a core | **Inconsistent** -- see DM-030 |
| Decay Factor | hardware_model.py:111, assembly.py:8 | Fixed-point fraction for LEAK (decay/256) | Yes |

---

## Design Rationale (Inline Code Comments)

### DM-025: Clamping Bus Range for Safety
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:76-79
- **Statement:** "# Clamp range to actual bus length"
- **Implied Requirement:** The ACC instruction must gracefully handle cases where the operand-specified input range exceeds the actual bus size, by clamping to available data rather than raising an error.
- **Confidence:** Medium -- the comment documents defensive coding but doesn't explain why the mismatch might occur.

### DM-026: Mutable Counter Closure Pattern
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py`:61
- **Statement:** "core_counter = [0]  # mutable counter for closure"
- **Implied Requirement:** Core IDs are assigned sequentially during code generation via a closure pattern. This is a Python implementation detail but reveals that core assignment is sequential, not optimized.
- **Confidence:** High -- explicit.

### DM-027: Symmetric Quantization Choice
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py`:62
- **Statement:** "Uses symmetric quantization: q = round(w / scale), scale = max(|w|) / 127."
- **Implied Requirement:** Weight quantization must use symmetric quantization (zero point = 0). This simplifies the integer arithmetic since no zero-point correction is needed during accumulation.
- **Confidence:** High -- formula explicitly documented.

### DM-028: Asymmetric Quantization for Activations
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py`:87
- **Statement:** "Uses asymmetric quantization for ReLU outputs (min=0)."
- **Implied Requirement:** Activation quantization uses asymmetric quantization because post-ReLU activations are non-negative. This utilizes the full 0-255 unsigned range more efficiently.
- **Confidence:** High -- explicit with rationale.

### DM-029: Global Scale Calibration
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py`:48-49
- **Statement:** `calibrate_mode="global_scale", global_scale=8.0`
- **Implied Requirement:** The TVM quantization path uses global scale calibration with a fixed scale of 8.0, not per-channel or calibration-dataset-based scaling. This is a simplification; the `calibration_dataset` parameter exists in the function signature but is unused.
- **Confidence:** High -- visible in code with comment.

---

## Inconsistencies Between Documentation and Code

### DM-030: Accumulator Width Inconsistency (int16 vs int32)
- **Source:** Multiple locations
- **Documentation says int16:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md`:17 -- "int8 weights, int16 accumulator"
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:5 -- "int8 weights, int16 accumulator"
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py`:4 -- "int8 weights, int16 accumulator"
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/notebooks/01_spikecore_tvm.ipynb` cell-0 -- "int32 accumulators"
  - Notebook cell 4 markdown: "int16 accumulators"
- **Documentation says int32:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/README.md`:19 -- "Accumulator | int32 (32-bit signed)"
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/notebooks/01_spikecore_tvm.ipynb` cell-0 -- "int32 accumulators"
- **Code actually uses int32:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:81-82 -- `.astype(np.int32)` for dot product
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:73 -- docstring says "int32 arithmetic"
  - Activation bus uses `np.int16` at line 141
- **Implied Issue:** There is a specification conflict. The design document and several module docstrings say "int16 accumulator," but the README says "int32" and the code actually performs int32 arithmetic. The bus is int16 but the accumulator computation is int32. This appears to be a documentation drift where early design specified int16 but implementation upgraded to int32.

### DM-031: Notebook Cell-0 Internal Inconsistency
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/notebooks/01_spikecore_tvm.ipynb` cell-0
- **Statement:** "**SpikeCore hardware model:** 128 neuron cores, int8 weights, int32 accumulators"
- **vs.** Cell 4 markdown (cell-7): "SpikeCore is integer-only: **int8 weights**, **int16 accumulators**."
- **Implied Issue:** Even within the same notebook, the accumulator width description is inconsistent (int32 in cell 0, int16 in cell 4).

---

## Deferred Work Items

### DM-032: Phase 2 -- MLIR Extension
- **Marker:** Phase 2 Roadmap item
- **Location:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/README.md`:117 and `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md`:72
- **Statement:** "MLIR extension: torch-mlir -> custom `spikecore` MLIR dialect -> same simulator" / "02_spikecore_mlir.ipynb -- torch-mlir -> custom spikecore MLIR dialect -> same simulator"
- **Implied Work:** A second notebook implementing a torch-mlir-based compilation path to a custom MLIR dialect, feeding into the same SpikeCore simulator. This would demonstrate the MLIR approach as an alternative to the TVM BYOC pipeline.
- **Priority Signal:** Listed first in Phase 2; explicitly deferred from Phase 1 with documented rationale (complexity).

### DM-033: Phase 2 -- Convolutional Models
- **Marker:** Phase 2 Roadmap item
- **Location:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/README.md`:118
- **Statement:** "Convolutional models: Event-driven convolutions for vision tasks"
- **Implied Work:** Extending the SpikeCore ISA and compiler to support convolutional operations, likely requiring new instruction types or a convolution-to-dense decomposition strategy.
- **Priority Signal:** Listed second in Phase 2.

### DM-034: Phase 2 -- Multi-Chip Simulation
- **Marker:** Phase 2 Roadmap item
- **Location:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/README.md`:119
- **Statement:** "Multi-chip simulation: Spike routing between SpikeCore chips"
- **Implied Work:** Extending the simulator to model inter-chip communication, requiring spike routing, chip-to-chip latency, and potentially a network-on-chip model. This maps to Loihi's multi-chip deployments.
- **Priority Signal:** Listed third in Phase 2.

### DM-035: Phase 2 -- Power/Latency Estimation
- **Marker:** Phase 2 Roadmap item
- **Location:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/README.md`:120
- **Statement:** "Power/latency estimation: Energy model based on spike counts and memory access patterns"
- **Implied Work:** Adding an energy/latency model to the simulator that estimates power consumption and timing based on spike activity and memory access patterns. This is critical for neuromorphic hardware evaluation.
- **Priority Signal:** Listed fourth in Phase 2.

### DM-036: Phase 2 -- Lava Comparison
- **Marker:** Phase 2 Roadmap item
- **Location:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/README.md`:121
- **Statement:** "Lava comparison: Side-by-side with actual Intel Lava/Loihi workflow"
- **Implied Work:** Adding a comparison between the SpikeCore pipeline and the actual Intel Lava framework / Loihi hardware workflow, validating that SpikeCore faithfully models the real compilation challenges.
- **Priority Signal:** Listed last in Phase 2; highest real-world validation value.

### DM-037: Unused calibration_dataset Parameter
- **Marker:** Implicit deferred work (function parameter exists but is unused)
- **Location:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py`:25
- **Statement:** `calibration_dataset: np.ndarray | None = None` (parameter declared but never used in the function body)
- **Implied Work:** The quantization function signature anticipates calibration-dataset-based quantization (e.g., per-channel or percentile-based scaling), but the current implementation only uses global_scale. This is a hook for future per-sample calibration.
- **Priority Signal:** Low -- parameter is optional with None default.

---

## Verification Criteria (From Design Document)

### DM-038: Explicit Verification Criteria
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md`:63-68
- **Statement:**
  1. "Docker build: `docker compose build` completes without errors"
  2. "Unit tests: `pytest tests/ -v` -- all green"
  3. "Notebook run: 'Run All Cells' completes without errors"
  4. "Round-trip accuracy: SpikeCore classification matches PyTorch top-1 on >= 70% of test samples"
  5. "Visual inspection: spike raster shows meaningful temporal activity patterns"
- **Implied Requirements:** These are acceptance criteria. The 70% match rate is the quantitative accuracy threshold. The spike raster visual quality requirement is qualitative.

### DM-039: Quantization Error Tolerance in Round-Trip Test
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_roundtrip.py`:145-149
- **Statement:** "Note: quantization introduces error, so we allow some mismatch. The plan targets >= 90% match on MNIST; on this synthetic data with fewer features, we target >= 70%."
- **Implied Requirement:** Two accuracy thresholds exist: 90% for MNIST (notebook/design doc context) and 70% for synthetic test data (CI context). The lower threshold for synthetic data is explicitly justified by the reduced feature space.

---

## Real-World Domain Mapping (Developer-Stated Equivalences)

### DM-040: Explicit Loihi Mapping Table
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/README.md`:104-113
- **Statement:** Full mapping table provided:
  - ACC instruction -> Loihi dendritic accumulation / synaptic integration
  - FIRE instruction -> Loihi axon compartment / spike generation
  - LEAK instruction -> Loihi compartment leak current / membrane decay
  - BYOC pattern matching -> Lava compiler's operator fusion & mapping
  - Graph partitioning -> Lava's host <-> neuromorphic chip splitting
  - int8 quantization -> Loihi's native 1-9 bit weight precision
  - Core-local weight memory -> Loihi's synapse memory per neurocore
  - Event-driven simulation -> Loihi's asynchronous spike-based execution
- **Implied Requirement:** Every component in SpikeCore has a documented real-world counterpart in the Intel Loihi/Lava ecosystem. This mapping table serves as a validation checklist: the system is complete when all listed equivalences are demonstrated.

---

## Notebook as Documentation (Inline Narrative)

### DM-041: Relay IR Explained as Analogous to ONNX/torch.fx
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/notebooks/01_spikecore_tvm.ipynb` cell-5
- **Statement:** "The Relay IR is TVM's high-level graph representation -- analogous to ONNX or torch.fx but designed for compiler transformations."
- **Implied Requirement:** The notebook serves an educational purpose, situating Relay IR relative to industry-standard graph representations.

### DM-042: BYOC Registration Stated as "Exactly How Intel Would Register Loihi"
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/notebooks/01_spikecore_tvm.ipynb` cell-9
- **Statement:** "This is exactly how Intel would register Loihi as a BYOC target in TVM."
- **Implied Requirement:** The BYOC registration code must faithfully represent the actual pattern used for real hardware targets in TVM. This is not a pedagogical simplification -- it is claimed to be the production approach.

### DM-043: Rate-Coded vs. Temporal Inference Distinction
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py`:187
- **Statement:** "For single-timestep rate-coded inference, the accumulator values (before FIRE) represent the layer's output activations."
- **Implied Requirement:** The system supports two inference modes: (1) single-timestep rate-coded (accumulator = logits) and (2) multi-timestep temporal (spike counts over time). The `get_output_activations` method is specifically for rate-coded mode.

### DM-044: Spike Raster as STDP Foundation
- **Source:** `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/notebooks/01_spikecore_tvm.ipynb` cell-19
- **Statement:** "In a real neuromorphic chip, this temporal activity pattern encodes information through spike timing -- the basis of spike-timing-dependent plasticity (STDP)."
- **Implied Requirement:** The spike raster visualization is not merely decorative -- it demonstrates the temporal coding that enables learning in real neuromorphic systems (STDP). This connects the simulation to on-chip learning research.

---

## Gaps

1. **No CHANGELOG or version history.** The project appears to be at initial release with no documented evolution timeline.

2. **No CONTRIBUTING.md or development process documentation.** This is consistent with a single-developer demonstration project.

3. **No LICENSE file.** The project's licensing status is undocumented.

4. **No .gitignore file** (except the auto-generated pytest cache one). Suggests the repo may not yet be version-controlled.

5. **No pyproject.toml, setup.py, or setup.cfg.** The package is not installable via pip; it relies on PYTHONPATH manipulation.

6. **Zero TODO/FIXME/HACK/XXX markers.** While this could indicate clean code, it is unusual for a project with an acknowledged Phase 2. Deferred work is only captured in README/design doc, not in code-level markers near the relevant implementation sites.

7. **Accumulator width inconsistency (DM-030/DM-031).** The design document says int16; the README and code say int32. This is a specification conflict that needs resolution.

8. **No documentation for the quantized forward pass algorithm.** The `_spikecore_predict` function in `test_roundtrip.py` (lines 89-124) contains a detailed docstring describing the dequantize-requantize inter-layer pipeline, but this algorithm is not documented in the library's own `quantize.py` or in the design document. It exists only in test code.

9. **BYOC codegen hardcodes dimensions.** The TVM BYOC callback at `byoc_codegen.py`:82 emits hardcoded `spike_in_[0:64]` regardless of actual layer dimensions. The comment "Dense + activation -> ACC + FIRE" does not acknowledge this limitation. The standalone path does not share this hardcoding.

10. **No documentation on the cost estimator.** The `relay.ext.spikecore.cost_estimator` at `byoc_codegen.py`:112-114 always returns 1. There is no documentation discussing what a real cost model would consider (memory constraints, communication cost, etc.).

11. **No error handling documentation.** While `load_weights` raises `ValueError` for core overflow, there is no documentation about error modes in other paths (e.g., what happens when the program references a core_id beyond num_cores in ACC/FIRE/LEAK).

12. **External references list (README lines 125-131) includes no internal API documentation.** The references section cites external TVM and Loihi sources but does not point to any generated API docs or internal documentation beyond the design doc.

## Workflow Analyst Report

# Workflow Analysis Report

## Workflow Overview
- **Multi-step processes found:** 5
- **State machines identified:** 2
- **Cross-component flows:** 3

---

## Workflows

### Category: Neural Network Compilation Pipeline

#### WA-001: Full Compilation Pipeline (PyTorch to SpikeCore Execution)

This is the primary end-to-end workflow of the entire system. It takes a trained neural network from the PyTorch framework and compiles it down through multiple transformation stages into SpikeCore neuromorphic assembly, then executes it on a simulated hardware model.

- **Trigger:** User opens and executes the Jupyter notebook `01_spikecore_tvm.ipynb`, or programmatically invokes the compilation functions.
- **Actors:** User (Jupyter), PyTorch, TVM (optional), SpikeCore compiler, SpikeCore simulator.
- **Steps:**
  1. **Model Definition & Training** (notebook cell 2) -> Train a PyTorch `MNISTNet` MLP (784->64->10) on MNIST for 2 epochs.
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/notebooks/01_spikecore_tvm.ipynb` (cell-4)
  2. **Weight Extraction** (notebook cell 3) -> Extract `state_dict` as numpy arrays from the trained model.
     - File: `01_spikecore_tvm.ipynb` (cell-6)
  3. **Decision Point: TVM Available?**
     - If `HAS_TVM == True` -> TVM Relay Path (WA-002)
     - If `HAS_TVM == False` -> Standalone Path (WA-003)
  4. **Quantization** (notebook cell 4) -> Float32 weights -> int8 via `manual_quantize_weights()`.
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py:56-78`
  5. **Code Generation** (notebook cell 7) -> `compile_nn_to_spikecore()` emits SpikeCore `Instruction` objects.
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py:218-259`
  6. **Hardware Loading** (notebook cell 8) -> `SpikeCoreCPU.load_weights()` distributes int8 weights across cores, then `load_program()` loads the instruction list.
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:46-70`
  7. **Simulation** (notebook cell 8) -> `SpikeCoreCPU.run()` executes the program over N timesteps.
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:117-177`
  8. **Output Reading** -> `get_output_activations()` reads accumulator values from designated output cores.
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:183-193`
  9. **Comparison & Visualization** (notebook cells 9-10) -> PyTorch vs. SpikeCore top-1 predictions compared; spike raster, weight distributions, and output comparison charts plotted.
     - File: `01_spikecore_tvm.ipynb` (cell-18, cell-20)
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/visualize.py:17-228`

- **Happy Path:** Model trains to >95% accuracy on MNIST, quantization preserves prediction quality, compilation produces valid assembly, simulation produces spike activity, SpikeCore top-1 predictions match PyTorch on >=70% of samples (design doc target at `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docs/plans/2026-02-17-spikecore-lab-design.md:67`).

- **Error Paths:**
  - TVM import failure -> gracefully falls back to standalone path (`HAS_TVM = False` guards at `quantize.py:18-19`, `byoc_codegen.py:46-47`, `relay_patterns.py:26-27`)
  - Core overflow during weight loading -> `ValueError` raised at `hardware_model.py:65-67`: "need core N but only M available"
  - Invalid assembly text -> `ValueError` raised at `assembly.py:115`: "Cannot parse instruction"
  - Assembler line-level error wrapping at `assembly.py:127`: re-raises with line number context

- **End States:**
  - Successful: Compiled assembly listing + spike raster visualization + match rate percentage
  - Failed: Exception at any stage (no explicit recovery/retry mechanism)

- **Components:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/notebooks/01_spikecore_tvm.ipynb` (orchestration)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py` (quantization)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py` (compilation)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/assembly.py` (ISA / assembler)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py` (simulator)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/visualize.py` (visualization)

---

#### WA-002: TVM BYOC Compilation Path

This is the full-fidelity compilation path that uses Apache TVM's Bring Your Own Codegen framework to partition and compile the neural network graph. It requires TVM to be built from source (provided by the Docker container).

- **Trigger:** `HAS_TVM == True` (TVM successfully imported)
- **Actors:** TVM Relay, BYOC Framework, SpikeCore pattern table, SpikeCore codegen callback
- **Steps:**
  1. **PyTorch to Relay IR** -> `relay.frontend.from_pytorch(traced, input_info)` converts a JIT-traced PyTorch model to TVM Relay IR.
     - File: `01_spikecore_tvm.ipynb` (cell-6, line: `relay_mod, relay_params = relay.frontend.from_pytorch(traced, input_info)`)
  2. **TVM Quantization** -> `relay.quantize.quantize(mod, params)` with SpikeCore-specific qconfig: int8 weights, int8 inputs, int16 activations.
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py:22-53`
     - qconfig settings at lines 41-50: `nbit_input=8, nbit_weight=8, nbit_activation=16, global_scale=8.0`
  3. **Target Registration** -> `register_spikecore_target()` registers two TVM functions:
     - `relay.ext.spikecore` (codegen callback) at `byoc_codegen.py:104-110`
     - `relay.ext.spikecore.cost_estimator` (always returns 1, prefer offloading) at `byoc_codegen.py:112-114`
  4. **Graph Partitioning** -> `partition_for_spikecore()` runs a three-pass TVM pipeline:
     - `relay.transform.MergeComposite(patterns)` -> Fuses matching subgraphs using the pattern table
     - `relay.transform.AnnotateTarget(["spikecore"])` -> Marks fused composites for SpikeCore offloading
     - `relay.transform.PartitionGraph()` -> Splits into host vs. SpikeCore subgraphs
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py:117-148`
  5. **Pattern Matching Decision Points:**
     - `nn.dense + bias_add + relu` matched -> emits `ACC + FIRE + LEAK` (hidden layer)
     - `nn.dense + bias_add` matched -> emits `ACC` only (output layer)
     - `qnn.dense + add + clip(0,127)` matched -> emits `ACC + FIRE` (quantized path)
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/relay_patterns.py:29-78`
  6. **BYOC Codegen Callback** -> `_spikecore_codegen_callback()` traverses partitioned Relay subgraphs, visits composite functions, emits assembly text strings per pattern.
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py:54-92`
     - Composite dispatch at lines 80-88: pattern name contains "dense_relu", "dense_clip", "qnn_dense_clip", or "dense_bias"

- **Happy Path:** All dense layers match SpikeCore patterns; graph partitions into host (flatten) + 2 SpikeCore subgraphs; codegen emits valid assembly text.

- **Error Paths:**
  - TVM not available -> `RuntimeError("TVM is required...")` at `byoc_codegen.py:102`, `byoc_codegen.py:133`, `relay_patterns.py:71-72`, `quantize.py:38`
  - Unrecognized composite pattern -> silently skipped (no instruction emitted), core counter still increments at `byoc_codegen.py:88`

- **End States:**
  - Partitioned Relay module with SpikeCore subgraphs annotated
  - Assembly text strings embedded in TVM runtime modules

- **Components:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py` (registration, partitioning, codegen)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/relay_patterns.py` (pattern table)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py` (TVM quantization config)

---

#### WA-003: Standalone Compilation Path (No TVM)

This alternative compilation path bypasses TVM entirely, performing manual quantization and direct SpikeCore code generation from PyTorch weight arrays. It is the primary path used in testing and outside Docker.

- **Trigger:** `HAS_TVM == False`, or direct programmatic invocation of `compile_from_torch()` or `compile_nn_to_spikecore()`.
- **Actors:** User/test, quantizer, standalone compiler.
- **Steps:**
  1. **Entry via `compile_nn_to_spikecore(weights, biases, activations)`** or **`compile_from_torch(state_dict, layer_configs)`** 
     - `compile_nn_to_spikecore` at `byoc_codegen.py:218-259` takes raw weight/bias arrays
     - `compile_from_torch` at `byoc_codegen.py:155-215` takes a PyTorch-style state dict with layer configs
  2. **Per-layer iteration** -> For each layer in the network:
     - **Quantize weights** -> `manual_quantize_weights(w_fp32)` at `quantize.py:56-78`
       - Symmetric quantization: `scale = max(|w|) / 127`, `q = round(w / scale)`
       - Special case: zero weights -> returns `(zeros, scale=1.0, zp=0)` at `quantize.py:73-74`
     - **Compute FIRE shift** -> `_compute_fire_shift(fan_in)` at `byoc_codegen.py:26-37`
       - Formula: `shift = ceil(log2(fan_in)) + 7` to rescale int32 accumulator to int8 range
       - Special case: `fan_in <= 1` returns shift of 7 at `byoc_codegen.py:35-36`
     - **Decision Point: Has activation?**
       - If `activation == "relu"` -> emit `ACC + FIRE(threshold=0, shift=N) + LEAK(decay=240)` per output neuron (lines 200-209)
       - If `activation is None` -> emit `ACC` only per output neuron (lines 200-201, no FIRE/LEAK)
     - **Core ID assignment** -> Sequential: `core_id = core_offset + i`, `core_offset += out_features` (lines 198, 212)
  3. **Program termination** -> Append `HALT` instruction at `byoc_codegen.py:214` or `byoc_codegen.py:258`

- **Happy Path:** All layers quantized, all neurons mapped to unique cores within the 128-core limit, HALT appended.

- **Error Paths:**
  - Weight tensor has all zeros -> quantizer returns zeros with scale=1.0 (graceful, at `quantize.py:73-74`)
  - Core ID exceeds `num_cores` -> Not checked at compile time; would fail at `load_weights()` time in the simulator (`hardware_model.py:65-67`)

- **End States:**
  - Returns `(program: list[Instruction], quantized_weights: list[(ndarray, float)])` from `compile_from_torch`
  - Returns `(program, quantized_weights, quantized_biases)` from `compile_nn_to_spikecore`

- **Components:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py:155-259`
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/quantize.py:56-104`

---

### Category: Hardware Simulation

#### WA-004: SpikeCore Program Execution Lifecycle

This workflow describes how the SpikeCore simulator executes a compiled program on the virtual neuromorphic hardware, modeling the event-driven execution of spiking neurons across timesteps.

- **Trigger:** `SpikeCoreCPU.run(input_spikes, timesteps)` called at `hardware_model.py:117`.
- **Actors:** SpikeCoreCPU, NeuronCore array (128 cores), activation bus, spike log.
- **Steps:**
  1. **Initialization** (lines 132-142):
     - Clear spike log
     - Allocate zero spike_counts array (per-core, int32)
     - Reset all cores: `accumulator=0, membrane_potential=0, has_spiked=False` via `NeuronCore.reset()` at `hardware_model.py:30-33`
     - Create activation bus: `max(num_cores, len(input_spikes))` int16 zeros
     - Inject input spikes onto bus
  2. **Timestep Loop** (line 144) -> For each timestep `t` in `range(timesteps)`:
     - **Re-inject input** (lines 146-148) -> For `t > 0`, clear bus and reload input spikes
     - **Snapshot bus** (line 153) -> Take initial snapshot for layer-aware parallel semantics
     - **Instruction execution loop** (line 155) -> For each instruction in program:
       - **Decision: Instruction opcode?**
         - `Opcode.ACC` ->
           - **Layer boundary detection** (lines 157-161): Compare `(start, end)` range with `last_acc_range`; if different, refresh snapshot from live bus (simulates new layer reading updated activations)
           - Execute `_exec_acc(inst, snapshot)` at lines 72-84: int32 dot product of bus slice and weight slice, added to `core.accumulator`
         - `Opcode.FIRE` -> Execute `_exec_fire(inst, bus)` at lines 86-108:
           - Compute `total = accumulator + membrane_potential`
           - **Decision: total >= threshold?**
             - Yes (spike): Set `has_spiked=True`, right-shift by `shift` bits, clamp to int8, write to bus at `core_id` position, reset membrane and accumulator to 0
             - No (sub-threshold): Set `membrane_potential = total`, reset accumulator to 0, `has_spiked=False`
         - `Opcode.LEAK` -> Execute `_exec_leak(inst)` at lines 110-115: `membrane = (membrane * decay) >> 8` (fixed-point multiply by `decay/256`)
         - `Opcode.HALT` -> `break` out of instruction loop (line 168)
         - `Opcode.NOP` -> implicitly skipped (not handled, falls through)
     - **Collect spikes** (lines 171-175) -> Scan all cores; if `has_spiked`, append `(timestep, core_id)` to spike_log, increment spike_counts, reset `has_spiked`
  3. **Return** spike_counts array

- **Happy Path:** All instructions execute, hidden-layer neurons fire producing spikes on the bus that propagate to subsequent layer ACC instructions, output layer accumulates final scores.

- **Error Paths:**
  - ACC with bus range exceeding actual bus length -> clamped at `hardware_model.py:77`: `actual_end = min(end, len(bus))`; if `actual_end <= start`, returns early (line 78-79)
  - FIRE writes to bus position beyond bus length -> guarded by `if inst.core_id < len(bus)` at line 101
  - No explicit error for missing weights (would read default zeros from NeuronCore initialization)

- **End States:**
  - Returns `np.ndarray` of int32 spike counts per core
  - Side effects: `spike_log` populated (accessible via `get_spike_log()`), core state preserved (accessible via `get_output_activations()`)

- **State Transitions:** See State Machine SM-001 below.

- **Components:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:117-177` (run loop)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:72-115` (instruction executors)

---

#### WA-005: Assembly Round-Trip (Text <-> Instructions)

This workflow covers the bidirectional conversion between human-readable SpikeCore assembly text and the internal `Instruction` representation.

- **Trigger:** `assemble(text)` for text-to-instruction, `disassemble(program)` for instruction-to-text.
- **Actors:** Assembler parser, disassembler formatter.
- **Steps (Assembly direction):**
  1. **Input:** Multi-line text string
  2. **Per-line parsing** (line 121) -> For each line:
     - Strip whitespace, skip blank lines and comments (`#` or `//`) at `assembly.py:86`
     - Strip address prefix if present (e.g., `0000:`) at lines 89-90
     - **Decision: Opcode match?**
       - `NOP` / `HALT` -> simple construction (lines 93-96)
       - Regex match `_RE_ACC` -> extract `core_id, bank, start, end` (lines 98-101)
       - Regex match `_RE_FIRE` -> extract `core_id, threshold, optional_shift` (lines 103-108)
       - Regex match `_RE_LEAK` -> extract `core_id, decay` (lines 110-113)
       - No match -> `ValueError("Cannot parse instruction: ...")` at line 115
     - **Error wrapping** -> Line number added to error at `assembly.py:127`
  3. **Output:** `list[Instruction]`

- **Steps (Disassembly direction):**
  1. **Input:** `list[Instruction]`
  2. **Per-instruction formatting** via `disassemble_one()` at lines 43-63:
     - Opcode-specific text formatting with core_id, operands
     - FIRE includes optional `shift_N` suffix (lines 51-55)
  3. **Address prefix addition** (line 70) -> `{index:04d}:` prepended
  4. **Output:** Multi-line text string

- **Happy Path:** Text assembles cleanly; disassembled text can be re-assembled to produce identical instructions (verified by `test_roundtrip_disassemble_assemble` at `test_simulator.py:52-65`).

- **Error Paths:**
  - Invalid instruction text -> `ValueError` with line number context at `assembly.py:115,127`

- **Components:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/assembly.py:118-128` (assembler)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/assembly.py:43-71` (disassembler)

---

### Category: Testing & Verification

#### WA-006: Round-Trip Verification Workflow

This is the end-to-end test that validates the entire compilation pipeline produces correct results by comparing floating-point model predictions against quantized SpikeCore predictions.

- **Trigger:** `pytest tests/test_roundtrip.py` execution.
- **Actors:** pytest, numpy MLP trainer, SpikeCore compiler, quantized forward pass.
- **Steps:**
  1. **Generate synthetic data** -> `_make_synthetic_data()` creates 300 well-separated samples across 4 classes with 16 features.
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_roundtrip.py:16-33`
  2. **Train numpy MLP** -> `_train_numpy_mlp()` trains a 2-layer MLP (16->32->4) for 200 epochs using pure numpy gradient descent.
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_roundtrip.py:36-76`
  3. **Sanity check** -> `test_pytorch_accuracy` verifies float model achieves >90% training accuracy.
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_roundtrip.py:136-142`
  4. **Compile to SpikeCore** -> `compile_nn_to_spikecore(weights, biases, ["relu", None])` produces program + quantized weights.
     - File: `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_roundtrip.py:156-158`
  5. **Per-sample comparison** (100 samples) -> For each sample:
     - Float forward pass via `_pytorch_predict()` at lines 79-86
     - Quantized forward pass via `_spikecore_predict()` at lines 89-124: quantize input, int32 matmul, dequantize, ReLU for hidden layers
     - Compare top-1: `argmax(pt_logits) == argmax(sc_scores)`
  6. **Assertion** -> Match rate >= 70% required at line 177.
  7. **Structural verification** -> `test_compilation_produces_valid_assembly` checks HALT termination and correct ACC count (lines 181-195).
  8. **Spike activity verification** -> `test_spike_log_nonempty` loads program into simulator, runs it, asserts `len(spike_log) > 0` (lines 197-220).

- **Happy Path:** Float model trains well (>90%), quantization preserves predictions (>=70% match), assembly has correct structure, simulator produces spikes.

- **Error Paths:**
  - Float accuracy too low -> `AssertionError` at line 142 (indicates training failure, not pipeline failure)
  - Match rate below 70% -> `AssertionError` at line 177 (indicates quantization quality issue)
  - No spikes produced -> `AssertionError` at line 220 (indicates simulator or weight loading issue)

- **Components:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/tests/test_roundtrip.py` (entire file)
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/byoc_codegen.py:218-259`
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:117-177`

---

### Category: Infrastructure & Deployment

#### WA-007: Docker Build and Launch Workflow

This workflow covers building the development environment from scratch and launching the Jupyter notebook server.

- **Trigger:** User runs `docker compose up` or `docker compose build`.
- **Actors:** Docker, multi-stage Dockerfile, docker-compose.yml.
- **Steps:**
  1. **Stage 1: TVM Builder** (Dockerfile lines 4-32):
     - Base: `python:3.11-slim`
     - Install system build dependencies (cmake, git, llvm-15, clang-15, ninja-build)
     - Clone TVM source from GitHub (`--depth 1 --branch main --recursive`)
     - Configure cmake with LLVM-15 and Relay debug mode
     - Build with Ninja using all available cores
  2. **Stage 2: Runtime** (Dockerfile lines 34-63):
     - Base: fresh `python:3.11-slim`
     - Install runtime-only system libraries (libgomp1, llvm-15-runtime)
     - Copy built TVM from builder stage
     - Set environment variables: `TVM_HOME`, `PYTHONPATH`, `TVM_LIBRARY_PATH`
     - Install Python dependencies from `requirements.txt`
  3. **Container Launch** (docker-compose.yml + Dockerfile CMD):
     - Port mapping: 8888:8888
     - Volume mounts: `./notebooks`, `./spikecore`, `./tests` -> `/lab/*`
     - Environment: `PYTHONDONTWRITEBYTECODE=1`
     - CMD: `jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token=spikecore`
  4. **User Access** -> Browse to `http://localhost:8888/?token=spikecore`

- **Happy Path:** Docker builds both stages (~20+ min for TVM from source), container starts, Jupyter accessible at localhost:8888.

- **Error Paths:**
  - TVM build failure (network, cmake, LLVM version mismatch) -> Docker build fails at stage 1
  - Missing system dependencies at runtime -> TVM import fails, falls back to standalone path
  - Port 8888 already in use -> Docker compose error

- **End States:**
  - Running container with Jupyter, TVM, PyTorch, and SpikeCore all available
  - User can open `01_spikecore_tvm.ipynb` and Run All Cells

- **Components:**
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/Dockerfile`
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/docker-compose.yml`
  - `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/requirements.txt`

---

## State Machines

### SM-001: NeuronCore Lifecycle (per timestep)

Each of the 128 NeuronCore instances follows this state machine during program execution. The state is defined by the combination of `accumulator`, `membrane_potential`, and `has_spiked`.

| Current State | Event/Instruction | Next State | Guard | Side Effects |
|---|---|---|---|---|
| Idle (acc=0, mp=0, spiked=False) | `NeuronCore.reset()` | Idle | None | All state zeroed (`hardware_model.py:30-33`) |
| Idle | `ACC` instruction | Accumulating (acc>0) | `core_id` matches | `accumulator += dot(bus_slice, weight_slice)` (`hardware_model.py:72-84`) |
| Accumulating | `ACC` instruction | Accumulating (acc updated) | `core_id` matches | Accumulator further increased |
| Accumulating | `FIRE` (acc+mp >= threshold) | Spiked (spiked=True, mp=0, acc=0) | `total >= threshold` | Write scaled output to bus, reset acc and mp (`hardware_model.py:98-104`) |
| Accumulating | `FIRE` (acc+mp < threshold) | Sub-threshold (mp=total, acc=0, spiked=False) | `total < threshold` | Membrane absorbs accumulation (`hardware_model.py:106-108`) |
| Sub-threshold | `LEAK` instruction | Decayed (mp reduced) | `core_id` matches | `mp = (mp * decay) >> 8` (`hardware_model.py:114-115`) |
| Spiked | End of timestep | Idle (spiked cleared) | Spike collection phase | `has_spiked = False`, spike logged (`hardware_model.py:171-175`) |
| Sub-threshold | Next timestep `ACC` | Accumulating (acc>0, mp persists) | New timestep begins | Membrane potential carries over across timesteps |

**Terminal States:** None within a run; all cores return to Idle when `run()` is called (initial reset at `hardware_model.py:136-137`).

**Key insight:** The membrane potential persistence across timesteps (when FIRE misses threshold) is what makes this an event-driven spiking model rather than a simple feed-forward network. Sub-threshold accumulations can integrate over time, eventually crossing the threshold in a later timestep.

---

### SM-002: Program Execution State Machine

The SpikeCoreCPU itself has an implicit execution state.

| Current State | Event | Next State | Guard | Side Effects |
|---|---|---|---|---|
| Uninitialized | `__init__()` | Empty | None | 128 cores created, spike_log empty (`hardware_model.py:39-44`) |
| Empty | `load_program()` | Loaded | Program is list[Instruction] | Program stored (`hardware_model.py:46-48`) |
| Empty / Loaded | `load_weights()` | Weights Loaded | int8 array, core_offset valid | Weights distributed across cores (`hardware_model.py:50-70`) |
| Weights Loaded | `load_program()` | Ready | Program provided | Program stored |
| Ready (weights + program) | `run(input, timesteps)` | Executing | input_spikes provided | Spike log cleared, cores reset, bus created |
| Executing | HALT encountered or all instructions done | Timestep Complete | None | Spike collection phase |
| Timestep Complete | More timesteps remaining | Executing (next timestep) | `t < timesteps` | Bus re-initialized with input |
| Timestep Complete | Last timestep | Completed | `t == timesteps - 1` | Returns spike_counts |
| Completed | `get_spike_log()` | Completed | None | Returns spike history (`hardware_model.py:179-181`) |
| Completed | `get_output_activations()` | Completed | output_core_ids provided | Returns acc+mp from specified cores (`hardware_model.py:183-193`) |
| Completed | `run()` again | Executing | New run | Previous state wiped |

---

### SM-003: Compilation Path Selection

This implicit state machine governs which compilation path is taken, determined at module import time.

| Current State | Event | Next State | Guard |
|---|---|---|---|
| Init | `import tvm` succeeds | TVM Available | TVM library + dependencies present |
| Init | `import tvm` raises `ImportError` | TVM Unavailable | TVM not installed |
| TVM Available | `register_spikecore_target()` | BYOC Registered | One-time registration |
| BYOC Registered | `partition_for_spikecore(mod, params)` | Partitioned | Valid Relay module |
| Partitioned | BYOC codegen callback | Assembly Generated | Pattern matches found |
| TVM Unavailable | `compile_from_torch()` / `compile_nn_to_spikecore()` | Assembly Generated | Valid weights provided |

---

## Workflow Dependencies

| Workflow | Depends On | Shares State With | Conflicts With |
|---|---|---|---|
| WA-001 (Full Pipeline) | WA-002 or WA-003 (compilation), WA-004 (simulation) | All workflows share the `Instruction` and `Opcode` types from `assembly.py` | None |
| WA-002 (TVM BYOC Path) | TVM installed + built (WA-007 Docker), WA-005 (assembly text output) | Pattern table from `relay_patterns.py` | WA-003 (mutually exclusive runtime path) |
| WA-003 (Standalone Path) | Weight arrays (from PyTorch or numpy) | Quantization functions from `quantize.py` | WA-002 (mutually exclusive runtime path) |
| WA-004 (Simulation) | WA-002 or WA-003 (compiled program), loaded weights | NeuronCore state | Cannot run concurrently (single CPU instance) |
| WA-005 (Assembly Round-Trip) | None (self-contained) | `Instruction`/`Opcode` types shared everywhere | None |
| WA-006 (Round-Trip Test) | WA-003 (standalone compilation), WA-004 (simulation) | Test uses independent numpy model, not PyTorch | None |
| WA-007 (Docker Build) | Network access for TVM clone | Provides TVM for WA-002 | None |

---

## Cross-Component Flows

### Flow 1: Quantized Weight Data Flow

```
PyTorch state_dict (float32)
    |
    v  [quantize.py:56-78]  manual_quantize_weights()
int8 weight arrays + scale factors
    |
    |--- [byoc_codegen.py:190]  stored as quantized_weights return value
    |
    v  [hardware_model.py:50-70]  load_weights()
NeuronCore.weights[0:n] = w_int8[i, :n]  (distributed across cores)
    |
    v  [hardware_model.py:82-83]  _exec_acc()
weight_slice = core.weights[:n].astype(np.int32)
acc_value = sum(spike_slice * weight_slice)
```

### Flow 2: Activation Bus Inter-Layer Communication

```
Input Spikes (int8)
    |
    v  [hardware_model.py:142]  bus[:len(input_spikes)] = input_spikes
Activation Bus (int16, shared)
    |
    v  [hardware_model.py:153]  snapshot = bus.copy()  [layer boundary]
    |
    v  [hardware_model.py:162]  _exec_acc(inst, snapshot)  — reads from snapshot
    |
    v  [hardware_model.py:102]  _exec_fire() writes to bus[core_id]  — live bus updated
    |
    v  [hardware_model.py:160]  New layer ACC range detected → snapshot = bus.copy()
    |       (captures FIRE outputs from previous layer)
    v
Next layer reads updated snapshot containing prior layer outputs
```

### Flow 3: Notebook Orchestration Flow

```
Cell 2 (Train) → model.state_dict()
    |
Cell 3 (Export) → numpy arrays / Relay IR
    |
Cell 4 (Quantize) → int8 weights + scales
    |
Cell 5 (Register) → BYOC target in TVM
    |
Cell 6 (Partition) → host + spikecore subgraphs
    |
Cell 7 (Codegen) → program: list[Instruction]
    |
Cell 8 (Simulate) → spike_counts, spike_log, output_activations
    |
Cell 9 (Compare) → match_rate percentage
    |
Cell 10 (Visualize) → spike raster, weight histograms, pipeline summary
```

---

## Implicit Workflows

### IW-001: Layer Boundary Detection (Implicit in Simulator)

The simulator does not have an explicit concept of "layers." Instead, it infers layer boundaries by detecting when the ACC instruction's input range changes. At `/media/daniels/data/work/resume/2026 02 02 - Intel - AI Software Architect – Neuromorphic Computing/neuromorphic-lab/spikecore/hardware_model.py:156-161`:

```python
acc_range = (inst.operands[1], inst.operands[2])
if acc_range != last_acc_range:
    snapshot = bus.copy()
    last_acc_range = acc_range
```

This convention-based flow means that the compiler must generate ACC instructions grouped by layer (all same-range ACCs together) for correct simulation behavior. If instructions were interleaved across layers, the snapshot mechanism would produce incorrect results.

### IW-002: Core Offset Tracking (Implicit State Across Loads)

The `SpikeCoreCPU._next_core_offset` at `hardware_model.py:44` implicitly tracks how many cores have been filled across multiple `load_weights()` calls. When `core_offset=None` is passed (the default), the system auto-assigns cores sequentially:

```python
if core_offset is None:
    core_offset = self._next_core_offset
# ...
self._next_core_offset = core_offset + out_features
```

This creates an invisible dependency: `load_weights()` must be called in layer order for correct core assignment. There is no explicit enforcement or validation of this ordering.

### IW-003: Dual-Path Feature Parity (Convention-Based)

The TVM BYOC path (WA-002) and standalone path (WA-003) are designed to produce equivalent SpikeCore assembly, but this equivalence is maintained by convention, not by shared code. The TVM path emits text assembly via `_spikecore_codegen_callback()` (`byoc_codegen.py:54-92`), while the standalone path directly constructs `Instruction` objects (`byoc_codegen.py:197-214`). There is no automated test that verifies the two paths produce identical output for the same model.

---

## Gaps

### Gap 1: No Error Recovery in Simulation
The `SpikeCoreCPU.run()` method has no mechanism to handle or report errors during execution. If a core's accumulator overflows int32, the behavior is undefined (numpy will wrap). There is no simulation abort, no error logging, and no way to detect arithmetic overflow.

### Gap 2: No Core Capacity Validation at Compile Time
The standalone compiler (`compile_from_torch`, `compile_nn_to_spikecore`) does not check whether the total number of output neurons across all layers exceeds the hardware's 128-core limit. This is only caught at `load_weights()` time (`hardware_model.py:64-67`), creating a late failure after compilation has already succeeded.

### Gap 3: No TVM-to-Standalone Equivalence Test
While both compilation paths (TVM BYOC and standalone) are intended to produce functionally equivalent assembly, there is no test that runs both paths on the same model and compares their outputs. The round-trip test (`test_roundtrip.py`) only exercises the standalone path.

### Gap 4: NOP Instruction Has No Effect
The `NOP` opcode is defined in the ISA (`assembly.py:27`) and can be assembled/disassembled, but it is completely ignored during execution. The `run()` method's instruction dispatch at `hardware_model.py:155-168` has no handler for `Opcode.NOP`; it simply falls through the `if/elif` chain with no effect. While this is technically correct behavior, it is implicit rather than explicit.

### Gap 5: No HALT Validation
The compiler always appends `HALT` as the last instruction, but the simulator does not enforce its presence. If a program lacks `HALT`, execution simply runs through all instructions and then falls through naturally, which is functionally equivalent. This means `HALT` is semantically redundant in the current implementation, though it serves as a documentation/convention signal.

### Gap 6: Missing Bias Integration in Hardware Simulation
The `compile_nn_to_spikecore()` function quantizes biases (`byoc_codegen.py:244`) and returns them, but neither the standalone compiler nor the simulator incorporates bias values into the computation. The ACC instruction only performs weight-input dot products. Biases are quantized but never loaded into cores or applied during simulation. The round-trip test works around this by training without meaningful biases (initialized to zeros).

### Gap 7: Notebook Variable Dependency
Notebook cell 10 (`cell-20`) references a variable `inp_q_0` that is not defined in any earlier cell. The quantized input is created as `input_int8` in cell 8 (`cell-16`), suggesting a naming inconsistency that would cause a `NameError` at runtime if cells are executed in order. This indicates the notebook may have been edited after initial creation.

## Synthesis
- **Key Features:** 26 features across 10 areas identified. Dual TVM/standalone compilation paths with 18 features working without TVM and 5 requiring it. Single user role (ML Engineer/Researcher). Key capabilities: compile PyTorch models to SpikeCore assembly, simulate on virtual neuromorphic hardware, visualize results. Entry points include Python API, Jupyter notebook, Docker CLI, and pytest.
- **Core Concepts:** LIF (Leaky Integrate-and-Fire) neuron model as fundamental abstraction. 33 domain entities and rules across 8 domain areas: neuromorphic hardware architecture, ISA (5 opcodes: ACC/FIRE/LEAK/NOP/HALT), assembly language, compilation pipeline, quantization, simulation execution model, visualization/observability, and neural network model. Domain vocabulary mirrors Intel Loihi/Lava ecosystem. Key entities: NeuronCore, SpikeCoreCPU, Activation Bus, Instruction, Opcode.
- **Verified Behaviors:** 30 verified behaviors (BA-001 through BA-030) across 22 test functions in 3 test files and 6 test classes. Coverage spans assembly parsing, neuron core state management, SpikeCoreCPU simulation, weight quantization, BYOC code generation, and full round-trip pipeline. Coverage gaps in relay_patterns.py (0% coverage), visualize.py (0% coverage), multi-timestep execution, FIRE shift verification, activation bus clipping, and weight memory overflow.
- **Non-Functional Requirements:** 32 NFRs identified (IA-001 through IA-032) across security (5), performance (7), reliability (6), observability (5), and deployment (10).
- **Developer Intent:** 44 findings (DM-001 through DM-044). Key design rationale: TVM BYOC over custom LLVM backend, Docker for reproducibility, PyTorch CPU-only, MNIST MLP as minimal sufficient model. 6 deferred Phase 2 items. Critical inconsistency: int16 vs int32 accumulator documentation (DM-030).
- **Workflows:** 7 workflows (WA-001 through WA-007), 3 state machines, 3 cross-component flows, 3 implicit workflows, 7 gaps.
- **Agreements:** All six analysts agree on: dual-path architecture, 128-core/256-byte hardware model, LIF neuron model, sequential core allocation, int8 quantization bridge, event-driven timestep execution, single user role, graceful TVM degradation.
- **Tensions:** int16 vs int32 accumulator documentation inconsistency; biases quantized but never used in simulation; BYOC codegen hardcodes dimensions while standalone path computes dynamically.
- **Coverage Gaps:** No TVM integration tests, no visualization tests, no multi-timestep simulation tests, no FIRE shift verification test, no bias integration in simulation, no TVM-to-standalone equivalence test, no CI/CD pipeline, no structured logging.
