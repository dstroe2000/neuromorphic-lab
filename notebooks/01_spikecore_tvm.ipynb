{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# SpikeCore Lab — PyTorch → TVM BYOC → Neuromorphic Target\n\nThis notebook demonstrates the full compilation pipeline from a trained PyTorch model\nto a fictional neuromorphic hardware target (\"SpikeCore\") using TVM's BYOC framework.\n\n**Pipeline stages:**\n1. Train a 2-layer MLP on MNIST\n2. Export to TVM Relay IR\n3. Quantize float32 → int8\n4. Register SpikeCore as BYOC target\n5. Partition graph (host vs. SpikeCore subgraphs)\n6. Code generation → SpikeCore assembly\n7. Simulate on SpikeCore hardware model\n8. Compare PyTorch vs. SpikeCore outputs\n\n**SpikeCore hardware model:** 128 neuron cores, int8 weights, int32 accumulators,\n3 primitive ops (ACC, FIRE, LEAK), event-driven execution."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1 — Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for TVM availability\n",
    "try:\n",
    "    import tvm\n",
    "    from tvm import relay\n",
    "    HAS_TVM = True\n",
    "    print(f\"TVM version: {tvm.__version__}\")\n",
    "except ImportError:\n",
    "    HAS_TVM = False\n",
    "    print(\"TVM not available — using standalone compilation path\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# SpikeCore modules\n",
    "from spikecore.hardware_model import SpikeCoreCPU\n",
    "from spikecore.assembly import assemble, disassemble, Opcode\n",
    "from spikecore.byoc_codegen import compile_nn_to_spikecore\n",
    "from spikecore.quantize import manual_quantize_weights, manual_quantize_activations\n",
    "from spikecore.visualize import (\n",
    "    plot_spike_raster, plot_compilation_graph,\n",
    "    plot_weight_distribution, plot_comparison\n",
    ")\n",
    "\n",
    "print(\"All imports successful.\")\n",
    "print(f\"SpikeCore simulator: {SpikeCoreCPU().__class__.__name__} with 128 cores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2 — PyTorch Model: 2-Layer MLP for MNIST\n",
    "\n",
    "A minimal MLP: 784 → 64 (ReLU) → 10 (softmax). Trained for 2 epochs on MNIST.\n",
    "This is intentionally simple — the focus is the compilation pipeline, not the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    \"\"\"2-layer MLP for MNIST digit classification.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x.view(-1, 784))\n",
    "\n",
    "model = MNISTNet()\n",
    "print(model)\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Train on MNIST\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_data = datasets.MNIST('./data', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(2):\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(model(batch_x), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}: avg loss = {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        preds = model(batch_x).argmax(dim=1)\n",
    "        correct += (preds == batch_y).sum().item()\n",
    "print(f\"Test accuracy: {correct / len(test_data):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3 — Export to Relay IR\n",
    "\n",
    "If TVM is available, we use `relay.frontend.from_pytorch()` to convert the model.\n",
    "Otherwise, we extract weights directly from the PyTorch state dict.\n",
    "\n",
    "The Relay IR is TVM's high-level graph representation — analogous to ONNX or\n",
    "torch.fx but designed for compiler transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract PyTorch weights as numpy arrays\n",
    "state = {k: v.detach().numpy() for k, v in model.state_dict().items()}\n",
    "print(\"Extracted weights:\")\n",
    "for name, arr in state.items():\n",
    "    print(f\"  {name}: {arr.shape} ({arr.dtype})\")\n",
    "\n",
    "if HAS_TVM:\n",
    "    # TVM path: trace model and convert to Relay\n",
    "    dummy_input = torch.randn(1, 1, 28, 28)\n",
    "    traced = torch.jit.trace(model, dummy_input)\n",
    "    input_info = [(\"input0\", (1, 1, 28, 28))]\n",
    "    relay_mod, relay_params = relay.frontend.from_pytorch(traced, input_info)\n",
    "    print(\"\\n--- Relay IR ---\")\n",
    "    print(relay_mod[\"main\"])\n",
    "else:\n",
    "    print(\"\\n--- Equivalent Relay IR (for reference) ---\")\n",
    "    print(\"\"\"\n",
    "fn (%input0: Tensor[(1, 1, 28, 28), float32]) {\n",
    "  %0 = nn.batch_flatten(%input0);\n",
    "  %1 = nn.dense(%0, meta[relay.Constant][0] /* (64, 784) */);\n",
    "  %2 = nn.bias_add(%1, meta[relay.Constant][1] /* (64,) */);\n",
    "  %3 = nn.relu(%2);\n",
    "  %4 = nn.dense(%3, meta[relay.Constant][2] /* (10, 64) */);\n",
    "  %5 = nn.bias_add(%4, meta[relay.Constant][3] /* (10,) */);\n",
    "  %5\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4 — Quantize: float32 → int8\n",
    "\n",
    "SpikeCore is integer-only: **int8 weights**, **int16 accumulators**.\n",
    "We quantize the trained weights using symmetric quantization:\n",
    "\n",
    "$$q = \\text{round}\\left(\\frac{w}{\\text{scale}}\\right), \\quad \\text{scale} = \\frac{\\max|w|}{127}$$\n",
    "\n",
    "This is the same quantization scheme used by TVM's `qconfig` with `global_scale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize each layer's weights\n",
    "w1_fp = state['layers.0.weight']  # (64, 784)\n",
    "b1_fp = state['layers.0.bias']    # (64,)\n",
    "w2_fp = state['layers.2.weight']  # (10, 64)\n",
    "b2_fp = state['layers.2.bias']    # (10,)\n",
    "\n",
    "w1_int8, w1_scale, _ = manual_quantize_weights(w1_fp)\n",
    "w2_int8, w2_scale, _ = manual_quantize_weights(w2_fp)\n",
    "b1_int8, b1_scale, _ = manual_quantize_weights(b1_fp)\n",
    "b2_int8, b2_scale, _ = manual_quantize_weights(b2_fp)\n",
    "\n",
    "print(\"Quantization results:\")\n",
    "print(f\"  Layer 1 weights: {w1_fp.shape} fp32 → int8 (scale={w1_scale:.6f})\")\n",
    "print(f\"    Range: [{w1_int8.min()}, {w1_int8.max()}]\")\n",
    "print(f\"  Layer 2 weights: {w2_fp.shape} fp32 → int8 (scale={w2_scale:.6f})\")\n",
    "print(f\"    Range: [{w2_int8.min()}, {w2_int8.max()}]\")\n",
    "\n",
    "# Verify quantization error\n",
    "w1_reconstructed = w1_int8.astype(np.float32) * w1_scale\n",
    "quant_error = np.mean(np.abs(w1_fp - w1_reconstructed))\n",
    "print(f\"\\n  Layer 1 mean quantization error: {quant_error:.6f}\")\n",
    "print(f\"  Layer 1 mean weight magnitude:   {np.mean(np.abs(w1_fp)):.6f}\")\n",
    "print(f\"  Relative error: {quant_error / np.mean(np.abs(w1_fp)):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5 — Register SpikeCore BYOC Target\n",
    "\n",
    "In TVM's BYOC (Bring Your Own Codegen) framework, we register:\n",
    "1. **Pattern table** — which Relay subgraphs map to SpikeCore ops\n",
    "2. **Codegen callback** — how to emit SpikeCore assembly from matched patterns\n",
    "\n",
    "Pattern matching rules:\n",
    "- `nn.dense + bias_add + relu` → `ACC + FIRE` (hidden layer with activation)\n",
    "- `nn.dense + bias_add` → `ACC` (output layer, no activation)\n",
    "\n",
    "This is exactly how Intel would register Loihi as a BYOC target in TVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_TVM:\n",
    "    from spikecore.byoc_codegen import register_spikecore_target, partition_for_spikecore\n",
    "    from spikecore.relay_patterns import spikecore_pattern_table\n",
    "    \n",
    "    # Register the target\n",
    "    register_spikecore_target()\n",
    "    print(\"Registered 'spikecore' BYOC target in TVM\")\n",
    "    \n",
    "    # Show pattern table\n",
    "    patterns = spikecore_pattern_table()\n",
    "    print(f\"\\nPattern table ({len(patterns)} patterns):\")\n",
    "    for name, pattern in patterns:\n",
    "        print(f\"  {name}\")\n",
    "else:\n",
    "    print(\"BYOC target registration (reference — requires TVM):\")\n",
    "    print()\n",
    "    print(\"  @tvm.register_func('relay.ext.spikecore')\")\n",
    "    print(\"  def spikecore_compiler(func):\")\n",
    "    print(\"      # Traverse Relay subgraph → emit SpikeCore assembly\")\n",
    "    print(\"      return codegen(func)\")\n",
    "    print()\n",
    "    print(\"  Pattern table:\")\n",
    "    print(\"    spikecore.dense_relu  — nn.dense + bias_add + relu  → ACC + FIRE\")\n",
    "    print(\"    spikecore.dense_bias  — nn.dense + bias_add         → ACC\")\n",
    "    print(\"    spikecore.qnn_dense_clip — qnn.dense + add + clip   → ACC + FIRE (quantized)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6 — Partition Graph\n",
    "\n",
    "TVM's partitioning pipeline splits the Relay graph into:\n",
    "- **SpikeCore subgraphs** — offloaded to the neuromorphic accelerator\n",
    "- **Host subgraphs** — remain on the CPU\n",
    "\n",
    "Steps: `MergeComposite` → `AnnotateTarget` → `PartitionGraph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_TVM:\n",
    "    partitioned_mod = partition_for_spikecore(relay_mod, relay_params)\n",
    "    print(\"--- Partitioned Relay IR ---\")\n",
    "    print(partitioned_mod[\"main\"])\n",
    "else:\n",
    "    print(\"--- Partitioned Graph (reference) ---\")\n",
    "    print(\"\"\"\n",
    "fn (%input0: Tensor[(1, 1, 28, 28), float32]) {\n",
    "  %0 = nn.batch_flatten(%input0);              // [host]\n",
    "  %1 = @spikecore_dense_relu_0(%0);            // [spikecore] → ACC + FIRE\n",
    "  %2 = @spikecore_dense_bias_1(%1);            // [spikecore] → ACC\n",
    "  %2\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Visualize the partitioned graph\n",
    "layer_names = [\"flatten\", \"dense_64\\n+relu\", \"dense_10\"]\n",
    "layer_targets = [\"host\", \"spikecore\", \"spikecore\"]\n",
    "layer_shapes = [(784, 784), (784, 64), (64, 10)]\n",
    "\n",
    "fig = plot_compilation_graph(layer_names, layer_targets, layer_shapes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7 — Code Generation: Relay → SpikeCore Assembly\n",
    "\n",
    "The BYOC codegen callback traverses each partitioned subgraph and emits\n",
    "SpikeCore assembly instructions. Each output neuron becomes a core with:\n",
    "- `ACC` — weighted accumulate from input spikes\n",
    "- `FIRE` — threshold comparison + spike emission (for hidden layers)\n",
    "- `LEAK` — membrane potential decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile using the standalone path (works with or without TVM)\n",
    "weights = [w1_fp, w2_fp]\n",
    "biases = [b1_fp, b2_fp]\n",
    "activations = [\"relu\", None]\n",
    "\n",
    "program, q_weights, q_biases = compile_nn_to_spikecore(weights, biases, activations)\n",
    "\n",
    "print(f\"Compiled program: {len(program)} instructions\")\n",
    "print(f\"  ACC:  {sum(1 for i in program if i.opcode == Opcode.ACC)}\")\n",
    "print(f\"  FIRE: {sum(1 for i in program if i.opcode == Opcode.FIRE)}\")\n",
    "print(f\"  LEAK: {sum(1 for i in program if i.opcode == Opcode.LEAK)}\")\n",
    "print(f\"  HALT: {sum(1 for i in program if i.opcode == Opcode.HALT)}\")\n",
    "print()\n",
    "\n",
    "# Print first 20 instructions\n",
    "listing = disassemble(program)\n",
    "lines = listing.split('\\n')\n",
    "print(\"--- SpikeCore Assembly (first 20 instructions) ---\")\n",
    "for line in lines[:20]:\n",
    "    print(line)\n",
    "if len(lines) > 20:\n",
    "    print(f\"  ... ({len(lines) - 20} more instructions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8 — Simulate on SpikeCore Hardware Model\n",
    "\n",
    "The SpikeCore simulator executes the assembly on the virtual hardware:\n",
    "- 128 neuron cores with local int8 weight memory\n",
    "- Event-driven: spikes propagate between layers\n",
    "- Membrane potential accumulates across timesteps\n",
    "\n",
    "For this single-timestep rate-coded inference, the accumulator values\n",
    "directly represent output logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a test sample\n",
    "test_sample, test_label = test_data[0]\n",
    "test_flat = test_sample.view(-1).numpy()  # (784,)\n",
    "\n",
    "# Initialize SpikeCore CPU\n",
    "cpu = SpikeCoreCPU(num_cores=128)\n",
    "\n",
    "# Load quantized weights\n",
    "for layer_id, (w_int8, scale) in enumerate(q_weights):\n",
    "    cpu.load_weights(layer_id, w_int8)\n",
    "    print(f\"Loaded layer {layer_id}: {w_int8.shape} int8 weights onto cores\")\n",
    "\n",
    "# Quantize input\n",
    "input_abs_max = np.max(np.abs(test_flat))\n",
    "input_int8 = np.clip(\n",
    "    np.round(test_flat / input_abs_max * 127), -128, 127\n",
    ").astype(np.int8)\n",
    "print(f\"Input quantized: {test_flat.shape} fp32 → int8 (scale={input_abs_max/127:.6f})\")\n",
    "\n",
    "# Run simulation\n",
    "cpu.load_program(program)\n",
    "spike_counts = cpu.run(input_int8, timesteps=8)\n",
    "spike_log = cpu.get_spike_log()\n",
    "\n",
    "print(f\"\\nSimulation complete:\")\n",
    "print(f\"  Timesteps: 8\")\n",
    "print(f\"  Total spikes: {len(spike_log)}\")\n",
    "print(f\"  Active cores: {len(set(s[1] for s in spike_log))}\")\n",
    "\n",
    "# Read output layer activations (cores 64-73 = layer 2)\n",
    "output_cores = list(range(64, 74))\n",
    "sc_outputs = cpu.get_output_activations(output_cores)\n",
    "sc_pred = np.argmax(sc_outputs)\n",
    "print(f\"\\nSpikeCore output scores: {sc_outputs}\")\n",
    "print(f\"SpikeCore prediction: {sc_pred}\")\n",
    "print(f\"True label: {test_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9 — Compare: PyTorch vs. SpikeCore\n",
    "\n",
    "Run the same test samples through both the original PyTorch model and the\n",
    "SpikeCore simulator, comparing top-1 predictions. Quantization introduces\n",
    "some error, but the predictions should match on the vast majority of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def spikecore_quantized_forward(q_weights, x_float):\n    \"\"\"Quantized forward pass matching SpikeCore's integer arithmetic.\n    \n    Per layer: quantize input → int matmul (ACC) → dequantize → activation (FIRE).\n    This is what a properly calibrated neuromorphic compiler produces.\n    \"\"\"\n    x = x_float.copy()\n    for layer_idx, (w_int8, w_scale) in enumerate(q_weights):\n        x_abs_max = np.max(np.abs(x))\n        if x_abs_max < 1e-10:\n            return np.zeros(w_int8.shape[0], dtype=np.float32)\n        x_scale = x_abs_max / 127.0\n        x_q = np.clip(np.round(x / x_scale), -128, 127).astype(np.int32)\n        acc = x_q @ w_int8.astype(np.int32).T\n        x = acc.astype(np.float64) * x_scale * w_scale\n        if layer_idx < len(q_weights) - 1:\n            x = np.maximum(x, 0)  # ReLU (FIRE equivalent)\n    return x.astype(np.float32)\n\nn_compare = 100\nmatches = 0\nresults = []\n\nmodel.eval()\nfor i in range(n_compare):\n    sample, label = test_data[i]\n    flat = sample.view(-1).numpy()\n    \n    # PyTorch prediction\n    with torch.no_grad():\n        pt_logits = model(sample.unsqueeze(0)).numpy().flatten()\n    pt_probs = np.exp(pt_logits) / np.exp(pt_logits).sum()\n    pt_pred = np.argmax(pt_logits)\n    \n    # SpikeCore quantized prediction\n    sc_logits = spikecore_quantized_forward(q_weights, flat)\n    sc_pred = np.argmax(sc_logits)\n    \n    match = pt_pred == sc_pred\n    if match:\n        matches += 1\n    results.append((label, pt_pred, sc_pred, match))\n\nmatch_rate = matches / n_compare\nprint(f\"PyTorch vs SpikeCore comparison ({n_compare} samples):\")\nprint(f\"  Matches: {matches}/{n_compare} ({match_rate:.1%})\")\nprint(f\"  Mismatches: {n_compare - matches}\")\n\nmismatches = [(l, pt, sc) for l, pt, sc, m in results if not m]\nif mismatches:\n    print(f\"\\n  First mismatch: label={mismatches[0][0]}, \"\n          f\"PyTorch={mismatches[0][1]}, SpikeCore={mismatches[0][2]}\")\n\n# Side-by-side visualization for the first sample\nsample_0, label_0 = test_data[0]\nwith torch.no_grad():\n    pt_logits_0 = model(sample_0.unsqueeze(0)).numpy().flatten()\npt_probs_0 = np.exp(pt_logits_0) / np.exp(pt_logits_0).sum()\n\nflat_0 = sample_0.view(-1).numpy()\nsc_logits_0 = spikecore_quantized_forward(q_weights, flat_0)\nsc_probs_0 = np.exp(sc_logits_0) / np.exp(sc_logits_0).sum()\n\nfig = plot_comparison(pt_probs_0, sc_probs_0, title=f\"Sample 0 (label={label_0})\")\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10 — Visualize: Spike Raster & Weight Distribution\n",
    "\n",
    "**Spike raster**: Shows which neuron cores fire at each timestep.\n",
    "In a real neuromorphic chip, this temporal activity pattern encodes information\n",
    "through spike timing — the basis of spike-timing-dependent plasticity (STDP).\n",
    "\n",
    "**Weight distribution**: Shows the quantized int8 weight values.\n",
    "A bell-shaped distribution centered near zero is typical for trained networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multi-timestep simulation for richer spike activity\n",
    "cpu = SpikeCoreCPU(num_cores=128)\n",
    "for layer_id, (w_int8, scale) in enumerate(q_weights):\n",
    "    cpu.load_weights(layer_id, w_int8)\n",
    "\n",
    "cpu.load_program(program)\n",
    "spike_counts = cpu.run(inp_q_0, timesteps=16)\n",
    "spike_log = cpu.get_spike_log()\n",
    "\n",
    "print(f\"16-timestep simulation: {len(spike_log)} total spikes\")\n",
    "\n",
    "# Spike raster\n",
    "fig1 = plot_spike_raster(spike_log, num_cores=74, num_timesteps=16,\n",
    "                          title=\"SpikeCore — Spike Raster (MNIST sample)\")\n",
    "plt.show()\n",
    "\n",
    "# Weight distributions\n",
    "fig2, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "plot_weight_distribution(q_weights[0][0], \"Layer 1 (784→64)\", ax=axes[0])\n",
    "plot_weight_distribution(q_weights[1][0], \"Layer 2 (64→10)\", ax=axes[1])\n",
    "fig2.suptitle(\"Quantized Weight Distributions (int8)\", fontsize=13, fontweight=\"bold\")\n",
    "fig2.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PIPELINE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"1. PyTorch model:     MLP 784→64→10 ({sum(p.numel() for p in model.parameters()):,} params)\")\n",
    "print(f\"2. Relay IR:          nn.dense → bias_add → relu → nn.dense → bias_add\")\n",
    "print(f\"3. Quantization:      float32 → int8 (symmetric, scale per tensor)\")\n",
    "print(f\"4. BYOC partition:    2 SpikeCore subgraphs + 1 host (flatten)\")\n",
    "print(f\"5. SpikeCore ASM:     {len(program)} instructions ({sum(1 for i in program if i.opcode == Opcode.ACC)} ACC, {sum(1 for i in program if i.opcode == Opcode.FIRE)} FIRE, {sum(1 for i in program if i.opcode == Opcode.LEAK)} LEAK)\")\n",
    "print(f\"6. Simulation:        {len(spike_log)} spikes over 16 timesteps\")\n",
    "print(f\"7. Accuracy match:    {match_rate:.1%} top-1 agreement on {n_compare} test samples\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Real-world mapping:\")\n",
    "print(\"  SpikeCore ACC   → Loihi dendritic accumulation\")\n",
    "print(\"  SpikeCore FIRE  → Loihi axon/spike generation\")\n",
    "print(\"  SpikeCore LEAK  → Loihi compartment leak current\")\n",
    "print(\"  BYOC partition  → Lava compiler's graph splitting\")\n",
    "print(\"  int8 quant      → Loihi's native 1-9 bit weight precision\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}